@issue
Feature: Issue #32 "behave --junit-directory=xxx" fails if more than 1 level must be created

  Scenario:
    Given a new working directory
    And a file named "features/steps/steps.py" with:
      """
      from behave import given, when, then
      @given(u'passing')
      def step(context):
          pass
      """
    And a file named "features/issue32_1.feature" with:
      """
      Feature: One
        Scenario: One
            Given passing
      """

    When I run "behave --junit --junit-directory=report/test_results"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      1 step passed, 0 failed, 0 skipped, 0 undefined
      """
    And the directory "report/test_results" should exist@issue
Feature: Issue #30 "behave --version" runs features and shows no version

  Scenario: Ensure environment assumptions are correct (Sanity Check)
    Given a new working directory
    When I run "behave"
    Then it should fail
    And the command output should contain:
      """
      No steps directory in '{__WORKDIR__}/features'
      """

  Scenario: Ensure --version option is processed correctly
    Given a new working directory
    When I run "behave --version"
    Then it should pass
    And the command output should not contain:
      """
      No steps directory in '{__WORKDIR__}/features'
      """
@issue
Feature: Issue #35 Plain Formatter shows wrong steps when tag-selection is used

  Background: Test Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
      """
      from behave import given, when, then
      @given(u'the ninja has a third level black-belt')
      def step(context):
          pass
      @when(u'attacked by {opponent}')
      def step(context, opponent):
          pass
      @then(u'the ninja should {reaction}')
      def step(context, reaction):
          pass
      """
    And a file named "features/issue35_1.feature" with:
      """
      Feature: Using Tags with Features and Scenarios
        @one
        Scenario: Weaker opponent
            Given the ninja has a third level black-belt
            When attacked by a samurai
            Then the ninja should engage the opponent
        @two
        Scenario: Stronger opponent
            Given the ninja has a third level black-belt
            When attacked by Chuck Norris
            Then the ninja should run for his life
      """

  Scenario: Select First Scenario with Tag
    When I run "behave --no-timings -f plain --tags=@one features/issue35_1.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 1 skipped
      3 steps passed, 0 failed, 3 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Feature: Using Tags with Features and Scenarios
         Scenario: Weaker opponent
             Given the ninja has a third level black-belt ... passed
              When attacked by a samurai ... passed
              Then the ninja should engage the opponent ... passed
         Scenario: Stronger opponent
      """

  Scenario: Select Second Scenario with Tag
    When I run "behave --no-timings -f plain --tags=@two features/issue35_1.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 1 skipped
      3 steps passed, 0 failed, 3 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Feature: Using Tags with Features and Scenarios
         Scenario: Weaker opponent
         Scenario: Stronger opponent
             Given the ninja has a third level black-belt ... passed
              When attacked by Chuck Norris ... passed
              Then the ninja should run for his life ... passed
      """
@issue
Feature: Issue #40 Test Summary Scenario/Step Counts are incorrect for Scenario Outline

  As I user
  I want that each passed and each failed scenario is counted
  And I want that each passed and failed step in a ScenarioOutline is counted

  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      from behave import given, when, then
      @given(u'a step {outcome} with "{name}"')
      def step(context, outcome, name):
          context.name = name
          assert outcome == "passes"
      @when(u'a step {outcome} with "{name}"')
      def step(context, outcome, name):
          assert outcome == "passes"
          assert context.name == name
      @then(u'a step {outcome} with "{name}"')
      def step(context, outcome, name):
          assert outcome == "passes"
          assert context.name == name
      """

  Scenario: ScenarioOutline with Passing Steps
    Given a file named "features/issue40_1.feature" with:
      """
      Feature: Verify Scenario/Step Summary Pass Count with ScenarioOutline
        Scenario Outline:
          Given a step passes with "<name>"
          When  a step passes with "<name>"
          Then  a step passes with "<name>"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue40_1.feature"
    Then it should pass with:
      """
      2 scenarios passed, 0 failed, 0 skipped
      6 steps passed, 0 failed, 0 skipped, 0 undefined
      """

  Scenario: ScenarioOutline with Failing Given-Steps
    Given a file named "features/issue40_2G.feature" with:
      """
      Feature: Scenario/Step Summary Pass/Fail Count with ScenarioOutline
        Scenario Outline:
          Given a step fails with "<name>"
          When  a step passes with "<name>"
          Then  a step passes with "<name>"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue40_2G.feature"
    Then it should fail with:
      """
      0 scenarios passed, 2 failed, 0 skipped
      0 steps passed, 2 failed, 4 skipped, 0 undefined
      """

  Scenario: ScenarioOutline with Failing When-Steps
    Given a file named "features/issue40_2W.feature" with:
      """
      Feature: Scenario/Step Summary Pass/Fail Count with ScenarioOutline
        Scenario Outline:
          Given a step passes with "<name>"
          When  a step fails with "<name>"
          Then  a step passes with "<name>"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue40_2W.feature"
    Then it should fail with:
      """
      0 scenarios passed, 2 failed, 0 skipped
      2 steps passed, 2 failed, 2 skipped, 0 undefined
      """

  Scenario: ScenarioOutline with Failing Then-Steps
    Given a file named "features/issue40_2T.feature" with:
      """
      Feature: Scenario/Step Summary Pass/Fail Count with ScenarioOutline
        Scenario Outline:
          Given a step passes with "<name>"
          When  a step passes with "<name>"
          Then  a step fails with "<name>"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue40_2T.feature"
    Then it should fail with:
      """
      0 scenarios passed, 2 failed, 0 skipped
      4 steps passed, 2 failed, 0 skipped, 0 undefined
      """

  Scenario: ScenarioOutline with Mismatched When-Step Example Row
    Given a file named "features/issue40_3W.feature" with:
      """
      Feature: Scenario/Step Summary Pass/Fail Count with ScenarioOutline
        Scenario Outline:
          Given a step passes with "<name>"
          When  a step passes with "Alice"
          Then  a step passes with "<name>"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue40_3W.feature"
    Then it should fail with:
      """
      1 scenario passed, 1 failed, 0 skipped
      4 steps passed, 1 failed, 1 skipped, 0 undefined
      """

  Scenario: ScenarioOutline with Mismatched Then-Step Example Row
    Given a file named "features/issue40_3W.feature" with:
      """
      Feature: Scenario/Step Summary Pass/Fail Count with ScenarioOutline
        Scenario Outline:
          Given a step passes with "<name>"
          When  a step passes with "<name>"
          Then  a step passes with "Alice"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue40_3W.feature"
    Then it should fail with:
      """
      1 scenario passed, 1 failed, 0 skipped
      5 steps passed, 1 failed, 0 skipped, 0 undefined
      """

@issue
Feature: Issue #41 Missing Steps are duplicated in a Scenario Outline

  As I user
  I want that missing steps are reported only once.

  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      from behave import given, when, then
      @given(u'I enter a "{name}"')
      def step(context, name):
          context.name = name
      @when(u'I enter a "{name}"')
      def step(context, name):
          context.name = name
      @then(u'the name is "{name}"')
      def step(context, name):
          assert context.name == name
      """

  Scenario: Missing Given Step
    Given a file named "features/issue41_missing1.feature" with:
      """
      Feature: Missing Given-Step in a Scenario Outline
        Scenario Outline:
          Given an unknown step
          When  I enter a "<name>"
          Then  the name is "<name>"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue41_missing1.feature"
    Then it should fail with:
      """
      0 steps passed, 0 failed, 4 skipped, 2 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @given(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Given an unknown step')
      """
    But the command output should not contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @given(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Given an unknown step')
      @given(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Given an unknown step')
      """

  Scenario: Missing When Step
    Given a file named "features/issue41_missing2.feature" with:
      """
      Feature: Missing When-Step in a Scenario Outline
        Scenario Outline:
          Given I enter a "<name>"
          When  I use an unknown step
          Then  the name is "<name>"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue41_missing2.feature"
    Then it should fail with:
      """
      2 steps passed, 0 failed, 2 skipped, 2 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @when(u'I use an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When I use an unknown step')
      """
    But the command output should not contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @when(u'I use an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When I use an unknown step')
      @when(u'I use an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When I use an unknown step')
      """

  Scenario: Missing Then Step
    Given a file named "features/issue41_missing3.feature" with:
      """
      Feature: Missing Then-Step in a Scenario Outline
        Scenario Outline:
          Given I enter a "<name>"
          When  I enter a "<name>"
          Then  I use an unknown step
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c -f plain features/issue41_missing3.feature"
    Then it should fail with:
      """
      4 steps passed, 0 failed, 0 skipped, 2 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @then(u'I use an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Then I use an unknown step')
      """
    But the command output should not contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @then(u'I use an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Then I use an unknown step')
      @then(u'I use an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Then I use an unknown step')
      """


@issue
Feature: Issue #42 Nice to have snippets for all unimplemented steps taking into account of the tags fltering

  As a user
  I want that all undefined steps are reported,
  not only just the first one in a scenario.

  In addition, all known steps after the first undefined step in a scenario
  should be marked as skipped (even failing ones).


  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      from behave import given, when, then
      @given(u'I enter a "{name}"')
      def step(context, name):
          context.name = name
      @when(u'I enter a "{name}"')
      def step(context, name):
          context.name = name
      @then(u'the name is "{name}"')
      def step(context, name):
          assert context.name == name
      """

  Scenario: One undefined step in a scenario
    Given a file named "features/issue42_missing1.feature" with:
      """
      Feature: Missing Given-Step in a Scenario
        Scenario:
          Given an unknown step
          When  I enter a "Alice"
          Then  the name is "Alice"
      """
    When I run "behave -f plain features/issue42_missing1.feature"
    Then it should fail with:
      """
      0 steps passed, 0 failed, 2 skipped, 1 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @given(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Given an unknown step')
      """

  Scenario: Two undefined steps in a scenario
    Given a file named "features/issue42_missing2.feature" with:
      """
      Feature: Missing Given and When steps in a Scenario
        Scenario:
          Given an unknown step
          When  another unknown step
           And  I enter a "Alice"
          Then  the name is "Alice"
      """
    When I run "behave -f plain features/issue42_missing2.feature"
    Then it should fail with:
      """
      0 steps passed, 0 failed, 2 skipped, 2 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @given(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Given an unknown step')
      @when(u'another unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When another unknown step')
      """

  Scenario: Two undefined steps in the middle with passing steps
    Given a file named "features/issue42_missing3.feature" with:
      """
      Feature: Missing 2 When steps after passing step
        Scenario:
          When I enter a "Alice"
          And  an unknown step
          And  another unknown step
          Then the name is "Alice"
      """
    When I run "behave -f plain features/issue42_missing3.feature"
    Then it should fail with:
      """
      1 step passed, 0 failed, 1 skipped, 2 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @when(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When an unknown step')
      @when(u'another unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When another unknown step')
      """

  Scenario: Undefined steps are detected if they occur after a failing step
    Given a file named "features/issue42_missing4.feature" with:
      """
      Feature: Missing 2 When steps after passing step
        Scenario:
          When I enter a "Alice"
          Then the name is "Bob"
          And  an unknown step
          And  another unknown step
      """
    When I run "behave -f plain features/issue42_missing4.feature"
    Then it should fail with:
      """
      1 step passed, 1 failed, 0 skipped, 2 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @then(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Then an unknown step')
      @then(u'another unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Then another unknown step')
      """

  Scenario: Failing step after first undefined step should be marked as skipped
    Given a file named "features/issue42_missing4.feature" with:
      """
      Feature: Missing 2 When steps after passing step
        Scenario:
          When I enter a "Alice"
          And  an unknown step
          Then the name is "Bob"
          And  another unknown step
      """
    When I run "behave -f plain features/issue42_missing4.feature"
    Then it should fail with:
      """
      1 step passed, 0 failed, 1 skipped, 2 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @when(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When an unknown step')
      @then(u'another unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Then another unknown step')
      """

  Scenario: Two undefined steps in scenario outline
    Given a file named "features/issue42_missing5.feature" with:
      """
      Feature: Missing Given and When Step in a Scenario Outline
        Scenario Outline:
          Given an unknown step
          When  another unknown step
           And  I enter a "<name>"
          Then  the name is "<name>"
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -f plain features/issue42_missing5.feature"
    Then it should fail with:
      """
      0 steps passed, 0 failed, 4 skipped, 4 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @given(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Given an unknown step')
      @when(u'another unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When another unknown step')
      """

  Scenario: Two undefined steps and run with tags
    Given a file named "features/issue42_missing6.feature" with:
      """
      Feature: Missing steps in tagged scenarios
        @tag1
        Scenario:
          When I enter a "Alice"
          And  an unknown step
          Then the name is "Bob"
        @tag1
        Scenario:
          When I enter a "Alice"
          And  another unknown step
          Then the name is "Bob"
        @another_tag
        Scenario:
          When  I enter a "Alice"
          And   yet another unknown step
          Then  the name is "Bob"
      """
    When I run "behave -f plain --tags tag1 features/issue42_missing6.feature"
    Then it should fail with:
      """
      2 steps passed, 0 failed, 5 skipped, 2 undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @when(u'an unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When an unknown step')
      @when(u'another unknown step')
      def step_impl(context):
          raise NotImplementedError(u'STEP: When another unknown step')
      """
@issue
Feature: Issue #44 Shell-like comments are removed in Multiline Args

  As I user
  I want that multiline arguments (docstrings) contents are preserved.

  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      from behave import given, when, then
      from hamcrest import assert_that, equal_to
      @given(u'a multiline text argument with')
      def step(context):
          context.expected_text = context.text
      @then(u'the multiline text argument should be')
      def step(context):
          assert_that(context.text, equal_to(context.expected_text))
      """

  Scenario: Ensure shell comment lines are not filtered out in multiline text
    Given a file named "features/issue44_test.feature" with:
      '''
      Feature: Multiline text with shell comment lines
        Scenario:
          Given a multiline text argument with:
            """
            Lorem ipsum.
            # THIS IS A SHELL COMMENT.
            Ipsum lorem.
            """
          Then the multiline text argument should be:
            """
            Lorem ipsum.
            # THIS IS A SHELL COMMENT.
            Ipsum lorem.
            """
      '''
    When I run "behave -c -f pretty features/issue44_test.feature"
    Then it should pass
    And  the command output should contain:
        """
        # THIS IS A SHELL COMMENT.
        """
    But  the command output should not contain:
        """
        Lorem ipsum.
        Ipsum lorem.
        """

@issue
Feature: Issue #46 Behave returns 0 (SUCCESS) even in case of test failures

  As I behave user
  I want to detect test success or test failures
  By using the process return value, 0 (SUCCESS) and non-zero for failure.

  Background: Test Setup
    Given a new working directory
    Given a file named "features/steps/steps.py" with:
      """
      from behave import given
      @given(u'passing')
      def step(context):
          pass
      @given(u'failing')
      def step(context):
          assert False, "failing"
      """

  Scenario: Successful Execution
    Given a file named "features/passing.feature" with:
      """
      Feature: Passing
        Scenario: Passing Scenario Example
          Given passing
      """
    When I run "behave -c -q features/passing.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      1 step passed, 0 failed, 0 skipped, 0 undefined
      """

  Scenario: Failing Execution
    Given a file named "features/failing.feature" with:
      """
      Feature: Failing
        Scenario: Failing Scenario Example
          Given failing
      """
    When I run "behave -c -q features/failing.feature"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      0 scenarios passed, 1 failed, 0 skipped
      0 steps passed, 1 failed, 0 skipped, 0 undefined
      """

  Scenario: Passing and Failing Execution
    Given a file named "features/passing_and_failing.feature" with:
      """
      Feature: Passing and Failing
        Scenario: Passing Scenario Example
          Given passing
        Scenario: Failing Scenario Example
          Given failing
      """
    When I run "behave -c -q features/passing_and_failing.feature"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      1 scenario passed, 1 failed, 0 skipped
      1 step passed, 1 failed, 0 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Feature: Passing and Failing
        Scenario: Passing Scenario Example
          Given passing
        Scenario: Failing Scenario Example
          Given failing
            Assertion Failed: failing
      """

@issue
Feature: Issue #52 Summary counts are wrong with option --tags

  Wrong summary counts are shown for skipped and failed scenarios
  when option --tags=done is used (and some scenarios are skipped).


  Background: Test Setup
    Given a new working directory
    Given a file named "features/steps/steps.py" with:
      """
      from behave import given
      @given(u'passing')
      def step(context):
          pass
      @given(u'failing')
      def step(context):
          assert False, "failing"
      """

  Scenario: Successful Execution of Tagged Scenario
    Given a file named "features/tagged_scenario1.feature" with:
      """
      Feature: Passing tagged Scenario
        @done
        Scenario: P1
          Given passing
        @unimplemented
        Scenario: N1
          Given passing
        @unimplemented
        Scenario: N2
          Given passing
      """
    When I run "behave --junit -c --tags @done features/tagged_scenario1.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 2 skipped
      """

  Scenario: Failing Execution of Tagged Scenario
    Given a file named "features/tagged_scenario2.feature" with:
      """
      Feature: Failing tagged Scenario
        @done
        Scenario: F1
          Given failing
        @unimplemented
        Scenario: N1
          Given passing
        @unimplemented
        Scenario: N2
          Given passing
      """
    When I run "behave --junit -c --tags @done features/tagged_scenario2.feature"
    Then it should fail
    And  the command output should contain:
      """
      0 features passed, 1 failed, 0 skipped
      0 scenarios passed, 1 failed, 2 skipped
      """

@issue
Feature: Issue #59 Fatal error when using --format=json

  Using the JSON formatter caused a fatal error.

  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      from behave import given
      @given(u'passing')
      def step(context):
          pass
      """
    And   a file named "features/issue59_test.feature" with:
      """
      Feature: Passing tagged Scenario
        Scenario: P1
          Given passing
      """

  Scenario: Use the JSONFormatter
    When I run "behave --format=json features/issue59_test.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      """


@issue
Feature: Issue #63: 'ScenarioOutline' object has no attribute 'stdout'

  The problem occurs when "behave --junit ..." is used
  And a feature contains one or more ScenarioOutline(s).

  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      # -- OMIT: from __future__ import print_function
      from behave import given
      import sys
      def generate_output(step, outcome, name):
          # -- OMIT: print("{0}0 {1}: {2};".format(step, outcome, name))
          sys.stdout.write("{0}1 {1}: {2};\n".format(step, outcome, name))
          sys.stderr.write("{0}2 {1}: {2};\n".format(step, outcome, name))
      @given(u'a {outcome} step with "{name}"')
      def step(context, outcome, name):
          context.name = name
          generate_output("Given", outcome, name)
          assert outcome == "passing"
      @when(u'a {outcome} step with "{name}" occurs')
      def step(context, outcome, name):
          generate_output("When", outcome, name)
          assert outcome == "passing"
      @then(u'a {outcome} step with "{name}" is reached')
      def step(context, outcome, name):
          generate_output("Then", outcome, name)
          assert outcome == "passing"
          assert context.name == name
      """

  Scenario: ScenarioOutline with Passing Steps
    Given a file named "features/issue63_case1.feature" with:
      """
      Feature: ScenarioOutline with Passing Steps
        Scenario Outline:
          Given a passing step with "<name>"
          When  a passing step with "<name>" occurs
          Then  a passing step with "<name>" is reached
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c --junit features/issue63_case1.feature"
    Then it should pass with:
      """
      2 scenarios passed, 0 failed, 0 skipped
      6 steps passed, 0 failed, 0 skipped, 0 undefined
      """
    But the command output should not contain:
      """
      AttributeError: 'ScenarioOutline' object has no attribute 'stdout'
      """

  Scenario: ScenarioOutline with Passing and Failing Steps
    Given a file named "features/issue63_case2.feature" with:
      """
      Feature: ScenarioOutline with Passing and Failing Steps
        Scenario Outline:
          Given a passing step with "<name>"
          When  a failing step with "<name>" occurs
          Then  a passing step with "<name>" is reached
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c --junit features/issue63_case2.feature"
    Then it should fail with:
      """
      0 scenarios passed, 2 failed, 0 skipped
      2 steps passed, 2 failed, 2 skipped, 0 undefined
      """
    But the command output should not contain:
      """
      AttributeError: 'ScenarioOutline' object has no attribute 'stdout'
      """
    And the command output should not contain:
      """
      AttributeError: 'Scenario' object has no attribute 'exception'
      """
    And the command output should contain:
      """
      Captured stdout:
      Given1 passing: Alice;
      When1 failing: Alice;
      """
    And the command output should contain:
      """
      Captured stderr:
      Given2 passing: Alice;
      When2 failing: Alice;
      """


@issue
Feature: Issue #64 Exit status not set to 1 even there are failures in certain cases

  The behave exit status not always returns 1 when failure(s) occur.
  The problem was associated with the Feature.run() logic implementation.

  This problem was first discovered while verifying issue #52 (see comments).
  See also similar test when tags select a subset of scenarios.

  RELATED ISSUES:
    * issue #52

  Background: Test Setup
    Given a new working directory
    Given a file named "features/steps/steps.py" with:
      """
      from behave import given
      @given(u'passing')
      def step(context):
          pass
      @given(u'failing')
      def step(context):
          assert False, "failing"
      """

  Scenario: Failing in First Scenario
    Given a file named "features/issue64_case1.feature" with:
      """
      Feature: Failing in First Scenario
        Scenario:
          Given failing
        Scenario:
          Given passing
      """
    When I run "behave --format=plain features/issue64_case1.feature"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      1 scenario passed, 1 failed, 0 skipped
      """

  Scenario: Failing in Middle Scenario
    Given a file named "features/issue64_case2.feature" with:
      """
      Feature: Failing in Middle Scenario
        Scenario:
          Given passing
        Scenario:
          Given failing
        Scenario:
          Given passing
      """
    When I run "behave --format=plain features/issue64_case2.feature"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      2 scenarios passed, 1 failed, 0 skipped
      """

  Scenario: Failing in Last Scenario
    Given a file named "features/issue64_case3.feature" with:
      """
      Feature: Failing in Last Scenario
        Scenario:
          Given passing
        Scenario:
          Given passing
        Scenario:
          Given failing
      """
    When I run "behave --format=plain features/issue64_case3.feature"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      2 scenarios passed, 1 failed, 0 skipped
      """

  Scenario: Failing in First and Last Scenario
    Given a file named "features/issue64_case4.feature" with:
      """
      Feature: Failing in First and Last Scenario
        Scenario:
          Given failing
        Scenario:
          Given passing
        Scenario:
          Given failing
      """
    When I run "behave --format=plain features/issue64_case4.feature"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      1 scenario passed, 2 failed, 0 skipped
      """

@issue
Feature: Issue #65  Unrecognized --tag-help argument

  The "behave --help" output refers to the option "--tag-help"
  in the description of the "--tags" option.
  The correct option for more help on tags is "--tags-help".

  Scenario: Ensure environment assumptions are correct (Sanity Check)
    Given a new working directory
    When I run "behave --help"
    Then the command output should contain:
      """
      --tags-help
      """
    But  the command output should not contain:
      """
      --tag-help
      """

@issue
Feature: Issue #66: context.text and context.table are not cleared

  I noticed that context.table and context.text survive after the step is finished.


  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      from behave import given, when, then
      from hamcrest import assert_that, equal_to, is_not, is_, none
      import six
      @given(u'a step with multiline text')
      def step(context):
          assert context.text is not None
          assert context.text, "Ensure non-empty"
          assert isinstance(context.text, six.string_types)
      @given(u'a step with a table')
      def step(context):
          assert context.table is not None
      @when(u'I check the "context.{name}" attribute')
      def step(context, name):
          context.name  = name
          context.value = getattr(context, name, None)
      @then(u'its value is None')
      def step(context):
          assert_that(context.value, is_(none()))
      @then(u'its value is "{value}"')
      def step(context, value):
          assert_that(context.value, equal_to(value))
      @then(u'its value is not "{value}"')
      def step(context, value):
          assert_that(value, is_not(equal_to(context.value)))
      """

  Scenario: Ensure multiline text data is cleared for next step
    Given a file named "features/issue66_case1.feature" with:
      """
      Feature:
        Scenario:
          Given a step with multiline text:
            '''
            Alice, Bob and Charly
            '''
          When I check the "context.text" attribute
          Then its value is not "Alice, Bob and Charly"
          But  its value is None
      """
    When I run "behave -f plain features/issue66_case1.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      4 steps passed, 0 failed, 0 skipped, 0 undefined
      """

  Scenario: Ensure table data is cleared for next step
    Given a file named "features/issue66_case2.feature" with:
      """
      Feature:
        Scenario:
          Given a step with a table:
            | name  | gender |
            | Alice | female |
            | Bob   | male   |
          When I check the "context.table" attribute
          Then its value is None
      """
    When I run "behave -f plain features/issue66_case2.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """
@issue
Feature: Issue #67: JSON formatter cannot serialize tables.

  The JSON formatter cannot handle tables (currently):

    * Table as setup/intermediate/result table in steps of scenario
    * Examples tables in a ScenarioOutline

  A JSON exception occurs when such a feature file should be processed.


  Scenario: Scenario with Tables
    Given a new working directory
    And   a file named "features/steps/steps1.py" with:
      """
      from behave import given, when, then
      @given(u'I add the following employees')
      def step(context):
          pass  # -- SKIP: Table processing here.
      @when(u'I select department "{department}"')
      def step(context, department):
          context.department = department
      @then(u'I get the following employees')
      def step(context):
          pass  # -- SKIP: Table processing here.
      """
    And  a file named "features/issue67_case1.feature" with:
      """
      Feature: Scenario with Tables
        Scenario:
         Given I add the following employees:
            | name      | department  |
            | Alice     | Wonderland  |
            | Bob       | Moonwalk    |
          When I select department "Wonderland"
          Then I get the following employees:
            | name      | department  |
            | Alice     | Wonderland  |
      """
    When I run "behave -f json features/issue67_case1.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """
    But the command output should not contain:
      """
      TypeError: <Row [u'Alice', u'Wonderland']> is not JSON serializable
      """

  Scenario: ScenarioOutline with Examples Table
    Given a file named "features/steps/steps2.py" with:
      """
      from behave import given, when, then
      @given(u'a step with "{name}"')
      def step(context, name):
          context.name = name
      @when(u'a step with "{name}" occurs')
      def step(context, name):
          assert context.name == name
      @then(u'a step with "{name}" is reached')
      def step(context, name):
          assert context.name == name
      """
    And a file named "features/issue67_case2.feature" with:
      """
      Feature: ScenarioOutline with Examples Table
        Scenario Outline:
          Given a step with "<name>"
          When  a step with "<name>" occurs
          Then  a step with "<name>" is reached
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -f json features/issue67_case2.feature"
    Then it should pass with:
      """
      2 scenarios passed, 0 failed, 0 skipped
      6 steps passed, 0 failed, 0 skipped, 0 undefined
      """
@issue
Feature: Issue #69: JUnitReporter: Fault when processing ScenarioOutlines with failing steps

  The problem occurs when "behave --junit ..." is used
  And a feature contains one or more ScenarioOutline(s) with failing steps.

  The JUnitReport does not process ScenarioOutline correctly (logic-error).
  Therefore, Scenarios of a ScenarioOutline are processes as Scenario steps.
  This causes problems when the step.status is "failed".

  RELATED:
    * issue #63

  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      from behave import given
      @given(u'a {outcome} step with "{name}"')
      def step(context, outcome, name):
          context.name = name
          assert outcome == "passing"
      @when(u'a {outcome} step with "{name}" occurs')
      def step(context, outcome, name):
          assert outcome == "passing"
          assert context.name == name
      @then(u'a {outcome} step with "{name}" is reached')
      def step(context, outcome, name):
          assert outcome == "passing"
          assert context.name == name
      """

  Scenario: ScenarioOutline with Failing Steps
    Given a file named "features/issue63_case2.feature" with:
      """
      Feature: ScenarioOutline with Passing and Failing Steps
        Scenario Outline:
          Given a passing step with "<name>"
          When  a failing step with "<name>" occurs
          Then  a passing step with "<name>" is reached
        Examples:
            |name |
            |Alice|
            |Bob  |
      """
    When I run "behave -c --junit features/issue63_case2.feature"
    Then it should fail with:
      """
      0 scenarios passed, 2 failed, 0 skipped
      2 steps passed, 2 failed, 2 skipped, 0 undefined
      """
    But the command output should not contain:
      """
      AttributeError: 'Scenario' object has no attribute 'exception'
      """
    And the command output should not contain:
      """
      behave/reporter/junit.py
      """

@issue
Feature: Issue #72: Using 'GHERKIN_COLORS' fails with Exception

    > Trying: GHERKIN_COLORS=executing=white behave
    > It fails:
    >
    >    Traceback (most recent call last):
    >      ...
    >      File "/.../behave/formatter/ansi_escapes.py", line 38, in <module>
    >        escapes[alias] = ''.join([colors[c] for c in aliases[alias].split(',')])
    >    TypeError: list indices must be integers, not str
    >
    > The reason is that the global variable colors is defined twice in this module.
    > The second variable overrides/modifies the first (without intention).


  Scenario: Using GHERKIN_COLORS in new working dir
    Given a new working directory
     And I set the environment variable "GHERKIN_COLORS" to "executing=white"
    When I run "behave"
    Then it should fail with:
      """
      No steps directory in '{__WORKDIR__}/features'
      """
     But the command output should not contain:
      """
      Traceback (most recent call last):
      """
     And the command output should not contain:
      """
      TypeError: list indices must be integers, not str
      """

@issue
Feature: Issue #73: the current_matcher is not predictable

  . behave provides 2 matchers: ParseMatcher (parse) and RegexpMatcher (re).
  . The ParseMatcher is used per default when the test runner starts.
  .
  . A step definition file may change the matcher several times
  . by calling `use_step_matcher("re")` or `use_step_matcher("parse")`.
  . In order to make the writing of step definitions more predictable,
  . the matcher should be reset to the default matcher
  . before loading each step definition.
  .
  . A project can define its own default matcher by calling the
  . `use_step_matcher(...)` in the "environment.py" hook.
  . This matcher will be used as default before a step definition is loaded.


  Scenario: Verify that ParseMatcher is the default matcher
    Given a new working directory
    And   a file named "features/steps/parse_steps.py" with:
        """
        from behave import step
        @step(u'a step {outcome:w}')
        def step_passes(context, outcome):
            assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
        """
    And   a file named "features/passing.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
            When  a step passes
            Then  a step passes
        """
    When I run "behave -f plain features/passing.feature"
    Then it should pass with
        """
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """


  Scenario: Use only RegexMatcher in Step Definitions
    Given a new working directory
    And   a file named "features/environment.py" with:
        """
        from behave import use_step_matcher
        use_step_matcher("re")
        """
    And   a file named "features/steps/regexp_steps.py" with:
        """
        from behave import step
        @step(u'a step (?P<outcome>passes|fails)')
        def step_passes(context, outcome):
            assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
        """
    And   a file named "features/passing.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
            When  a step passes
            Then  a step passes
        """
    When I run "behave -f plain features/passing.feature"
    Then it should pass with
        """
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """


  Scenario: Use ParseMatcher and RegexMatcher in Step Definitions (default=re)
    Given a new working directory
    And   a file named "features/environment.py" with:
        """
        from behave import use_step_matcher
        use_step_matcher("re")
        """
     And   a file named "features/steps/eparse_steps.py" with:
         """
         from behave import step, use_step_matcher
         use_step_matcher("parse")
         @step(u'an extraordinary step {outcome:w}')
         def step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         """
    And   a file named "features/steps/regexp_steps.py" with:
        """
        from behave import step
        @step(u'a step (?P<outcome>passes|fails)')
        def step_passes(context, outcome):
            assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
        """
     And   a file named "features/steps/xparse_steps.py" with:
         """
         from behave import step, use_step_matcher
         use_step_matcher("parse")
         @step(u'another step {outcome:w}')
         def step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         """
   And   a file named "features/passing3.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
            When  another step passes
            Then  an extraordinary step passes
        """
    When I run "behave -f plain features/passing3.feature"
    Then it should pass with
        """
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """


  Scenario: Mix ParseMatcher and RegexMatcher in Step Definitions (default=re)
    Given a new working directory
    And   a file named "features/environment.py" with:
        """
        from behave import use_step_matcher
        use_step_matcher("re")
        """
     And   a file named "features/steps/given_steps.py" with:
         """
         from behave import step, use_step_matcher
         use_step_matcher("parse")
         @given(u'a step {outcome:w}')
         def given_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         use_step_matcher("re")
         @given(u'another step (?P<outcome>passes|fails)')
         def given_another_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         use_step_matcher("parse")
         @given(u'an extraordinary step {outcome:w}')
         def given_extraordinary_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         """
     And   a file named "features/steps/when_steps.py" with:
         """
         from behave import step, use_step_matcher
         @when(u'a step (?P<outcome>passes|fails)')
         def when_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         use_step_matcher("parse")
         @when(u'another step {outcome:w}')
         def when_another_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         use_step_matcher("re")
         @when(u'an extraordinary step (?P<outcome>passes|fails)')
         def when_extraordinary_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         """
     And   a file named "features/steps/then_steps.py" with:
         """
         from behave import step, use_step_matcher
         use_step_matcher("parse")
         @then(u'a step {outcome:w}')
         def then_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         use_step_matcher("re")
         @then(u'another step (?P<outcome>passes|fails)')
         def then_another_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         use_step_matcher("parse")
         @then(u'an extraordinary step {outcome:w}')
         def then_extraordinary_step_passes(context, outcome):
             assert outcome == "passes", "FAIL: outcome={0}".format(outcome)
         """
   And   a file named "features/passing3.feature" with:
        """
        Feature:
          Scenario: 1
            Given a step passes
            When  another step passes
            Then  an extraordinary step passes
          Scenario: 2
            Given another step passes
            When  an extraordinary step passes
            Then  a step passes
          Scenario: 3
            Given an extraordinary step passes
            When  a step passes
            Then  another step passes
        """
    When I run "behave -c -f pretty --no-timings features/passing3.feature"
    Then it should pass with:
        """
        3 scenarios passed, 0 failed, 0 skipped
        9 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature:  # features/passing3.feature:1
          Scenario: 1                         # features/passing3.feature:2
            Given a step passes               # features/steps/given_steps.py:4
            When another step passes          # features/steps/when_steps.py:8
            Then an extraordinary step passes # features/steps/then_steps.py:14
          Scenario: 2                         # features/passing3.feature:7
            Given another step passes         # features/steps/given_steps.py:9
            When an extraordinary step passes # features/steps/when_steps.py:13
            Then a step passes                # features/steps/then_steps.py:4
          Scenario: 3                          # features/passing3.feature:12
            Given an extraordinary step passes # features/steps/given_steps.py:14
            When a step passes                 # features/steps/when_steps.py:3
            Then another step passes           # features/steps/then_steps.py:9
        """

@issue
Feature: Issue #75: behave @features_from_text_file does not work

  . Feature of Cucumber. Reading the source code, I see it partly implemented.
  .
  .   $ behave @list_of_features.txt
  .   https://github.com/jeamland/behave/blob/master/behave/runner.py#L416:L430
  .
  . However it fails because:
  .  * it does not remove the @ from the path
  .  * it does not search the steps/ directory in the parents of the feature files themselves


  @reuse.colocated_test
  Scenario: Use feature listfile
    Given I use the current directory as working directory
    When I run "behave -f plain features/runner.feature_listfile.feature"
    Then it should pass

@issue
Feature: Issue #77: Does not capture stdout from sub-processes

  . My step functions are using wrapper objects to interact with SUT.
  . Those wrappers use this kind of thing to invoke executables:
  .
  .   subprocess.check_call('myprog', ..., stderr=subprocess.STDOUT)
  .
  . However, the output from those calls does not appear in the stdout
  . captured by behave when a step fails.


  Background: Test Setup
    Given a new working directory
    Given a file named "hello.py" with:
        """
        import sys
        def hello():
            result = 0
            args = sys.argv[1:]
            if args and args[0].startswith("--fail"):
                result = 1
                args   = args[1:]
            message = " ".join(args)
            sys.stdout.write("Hello {0}\n".format(message))
            sys.exit(result)
        if __name__ == "__main__":
            hello()
        """
    And   a file named "features/steps/subprocess_call_steps.py" with:
        """
        from behave import given, when, then
        import subprocess
        import os.path
        import sys
        PYTHON = sys.executable
        HERE = os.path.dirname(__file__)
        @when(u'I make a subprocess call "hello {commandline}"')
        def step(context, commandline):
            result = subprocess_call_hello(commandline.split())
            assert result == 0
        def subprocess_call_hello(args):
            command_args = [ PYTHON, "hello.py" ] + args
            result = subprocess.check_call(command_args, stderr=subprocess.STDOUT)
            return result
            # result = subprocess.check_output(command_args, stderr=subprocess.STDOUT)
            # return result
        """

  Scenario: Subprocess call shows generated output
    Given a file named "features/issue77_hello_OK.feature" with:
        """
        Feature:
          Scenario:
            When I make a subprocess call "hello world."
        """
    When I run "behave -f plain features/issue77_hello_OK.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        1 step passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Hello world.
        """

  Scenario: Subprocess call fails with captured output
    Given a file named "features/issue77_hello_FAIL.feature" with:
        """
        Feature:
          Scenario:
            When I make a subprocess call "hello --fail FAIL."
        """
    When I run "behave -f plain features/issue77_hello_FAIL.feature"
    Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        0 steps passed, 1 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Hello FAIL.
        """

@issue
Feature: Issue #80: source file names not properly printed with python3

  . $ behave -f pretty example/example.feature
  . Scenario: run a simple test         # example/example.feature:3
  .    Given we have behave installed   # <string>:3
  .    When we implement a test         # <string>:7
  .    Then behave will test it for us! # <string>:11


  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
        """
        from behave import given, when, then
        @given(u'a step passes')
        def step(context):
            pass
        @when(u'a step passes')
        def step(context):
            pass
        @then(u'a step passes')
        def step(context):
            pass
        """
    And   a file named "features/basic.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
            When  a step passes
            Then  a step passes
        """

  Scenario: Show step locations
    When I run "behave -c -f pretty --no-timings features/basic.feature"
    Then it should pass
    And the command output should contain:
        """
        Feature:  # features/basic.feature:1
          Scenario:             # features/basic.feature:2
            Given a step passes # features/steps/steps.py:3
            When a step passes  # features/steps/steps.py:7
            Then a step passes  # features/steps/steps.py:11
        """
    And the command output should not contain "# <string>:"

@issue
Feature: Issue #81: Allow defining steps in a separate library

  . The current design forces steps.py to be in a particular folder.
  . This does not allow to reuse a common library of BDD steps across
  . multiple software projects in a company.
  . It would be great if one could define a separate lib with common steps
  . (e.g. steps4mycompany.py)


  Background: Test Setup
    Given a new working directory
    And   an empty file named "step_library42/__init__.py"
    And   a file named "step_library42/alice_steps.py" with:
        """
        # -- ALICE-STEPS: Anonymous step names.
        from behave import given, when, then
        @given(u'I use the step library "{library}"')
        def step(context, library):
            pass
        @when(u'I use steps from this step library')
        def step(context):
            pass
        @then(u'these steps are executed')
        def step(context):
            pass
        """
    And   a file named "features/use_step_library.feature" with:
        """
        Feature:
          Scenario:
            Given I use the step library "alice"
            When  I use steps from this step library
            Then  these steps are executed
        """

  Scenario: Proof of Concept
    Given a file named "features/steps/use_step_libs.py" with:
        """
        from step_library42.alice_steps import *
        """
    When I run "behave --no-timings -f plain features/use_step_library.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature:
           Scenario:
             Given I use the step library "alice" ... passed
              When I use steps from this step library ... passed
              Then these steps are executed ... passed
        """

  Scenario: With --format=pretty
    Given a file named "features/steps/use_step_libs.py" with:
        """
        from step_library42.alice_steps import *
        """
    When I run "behave -c -f pretty features/use_step_library.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature:  # features/use_step_library.feature:1
          Scenario:                                 # features/use_step_library.feature:2
            Given I use the step library "alice"    # step_library42/alice_steps.py:4
            When I use steps from this step library # step_library42/alice_steps.py:8
            Then these steps are executed           # step_library42/alice_steps.py:12
        """

  Scenario: Selective step import from step library
    Given a file named "step_library42/bob_steps.py" with:
        """
        # -- BOB-STEPS: Explicit step function names (otherwise same as alice).
        from behave import given, when, then
        @given(u'I use the step library "{library}"')
        def given_I_use_the_step_library(context, library):
            pass
        @when(u'I use steps from this step library')
        def when_I_use_steps_from_this_step_library(context):
            pass
        @then(u'these steps are executed')
        def then_these_steps_are_executed(context):
            pass
        """
    And a file named "features/steps/use_step_libs.py" with:
        """
        from step_library42.bob_steps import given_I_use_the_step_library
        from step_library42.bob_steps import when_I_use_steps_from_this_step_library
        from step_library42.bob_steps import then_these_steps_are_executed
        """
    When I run "behave -c -f pretty features/use_step_library.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature:  # features/use_step_library.feature:1
          Scenario:                                 # features/use_step_library.feature:2
            Given I use the step library "alice"    # step_library42/bob_steps.py:4
            When I use steps from this step library # step_library42/bob_steps.py:8
            Then these steps are executed           # step_library42/bob_steps.py:12
        """

  Scenario: Import step library in "environment.py"
    Given a file named "features/environment.py" with:
        """
        from step_library42.alice_steps import *
        """
    And   an empty file named "features/steps/__init__.py"
    When I run "behave -c -f pretty features/use_step_library.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature:  # features/use_step_library.feature:1
          Scenario:                                 # features/use_step_library.feature:2
            Given I use the step library "alice"    # step_library42/alice_steps.py:4
            When I use steps from this step library # step_library42/alice_steps.py:8
            Then these steps are executed           # step_library42/alice_steps.py:12
        """

@issue
Feature: Issue #83: behave.__main__:main() Various sys.exit issues

  . Currently, the main function has several issues related
  . to sys.exit() returncode usage:
  .
  . 1. sys.exit("string") is invalid, a number must be used:
  .    => Used in exception cases after run (ParseError, ConfigError)
  .
  . 2. On success, the main() function returns implicitly None
  .    instead of using sys.exit(0)
  .    => No statement at end of function after failed case.

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
        """
        from behave import step
        @step(u'a step passes')
        def step_passes(context):
            pass
        """

  Scenario: Successful test run
    Given a file named "features/passing.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
            When  a step passes
            Then  a step passes
        """
    When I run "behave -c features/passing.feature"
    Then it should pass
    And  the command returncode is "0"

  Scenario: ParseError occurs
    Given a file named "features/invalid_with_ParseError.feature" with:
        """
        Feature:
          Scenario: Invalid scenario which raises ParseError
            Given a step passes
            When2 a step passes
        """
    When I run "behave -c features/invalid_with_ParseError.feature"
    Then it should fail
    And  the command returncode is non-zero
    And  the command output should contain:
        """
        Failed to parse "{__WORKDIR__}/features/invalid_with_ParseError.feature"
        """

  Scenario: ConfigError occurs
    Given a new working directory
    And   a file named "features/passing2.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
        """
    When I run "behave -c features/passing2.feature"
    Then it should fail
    And  the command returncode is non-zero
    And  the command output should contain:
        """
        No steps directory in '{__WORKDIR__}/features'
        """

@issue
Feature: Issue #84: behave.runner behave does not reliably detected failed test runs

  . Behave does currently not reliably detected failed test runs and
  . therefore returns not sys.exit(1) at end of main().
  .
  . 1. behave.runner:Runner.run_with_paths() returns failed==True
  .    if last feature was successful and test runner does not stop
  .    after first failing feature.
  .
  . 2. Issue #64: Same problem in behave.model.Feature.run() with scenarios

  Scenario: Test Setup
    Given a new working directory
    And   a file named "features/passing.feature" with:
        """
        Feature: Passing
          Scenario:
            Given a step passes
            When  a step passes
            Then  a step passes
        """
    And   a file named "features/failing.feature" with:
        """
        Feature: Failing
          Scenario:
            Given a step fails
            When  a step fails
            Then  a step fails
        """
    And   a file named "features/steps/steps.py" with:
        """
        from behave import step
        @step(u'a step passes')
        def step_passes(context):
            pass
        @step(u'a step fails')
        def step_fails(context):
            assert False, "step: a step fails"
        """

  Scenario: First feature fails, second feature passes
    When I run "behave -f plain features/failing.feature features/passing.feature"
    Then it should fail with:
        """
        1 feature passed, 1 failed, 0 skipped
        1 scenario passed, 1 failed, 0 skipped
        3 steps passed, 1 failed, 2 skipped, 0 undefined
        """

  Scenario: First feature passes, second feature fails
    When I run "behave -f plain features/passing.feature features/failing.feature"
    Then it should fail with:
        """
        1 feature passed, 1 failed, 0 skipped
        1 scenario passed, 1 failed, 0 skipped
        3 steps passed, 1 failed, 2 skipped, 0 undefined
        """

  Scenario: First feature passes, second fails, last passes
    When I run "behave -f plain features/passing.feature features/failing.feature features/passing.feature"
    Then it should fail with:
        """
        2 features passed, 1 failed, 0 skipped
        2 scenarios passed, 1 failed, 0 skipped
        6 steps passed, 1 failed, 2 skipped, 0 undefined
        """

@issue
Feature: Issue #85: AssertionError with nested regex and pretty formatter

    | When --format=pretty is used
    | an AssertationError occurs for missing optional/nested-groups.
    | When --format=plain is used, everything is fine
  Scenario: Test Setup
    Given a new working directory
    And   a file named "features/steps/regexp_steps.py" with:
        """
        from __future__ import print_function
        from behave import given, when, then, use_step_matcher
        @given(u'a {re_category} regular expression "{pattern}"')
        def impl(context, re_category, pattern):
            pass
        @then(u'the parameter "{name}" is "{expected_value}"')
        def impl(context, name, expected_value):
            actual_value = getattr(context, name, None)
            if actual_value is None:
                actual_value = ""
            assert hasattr(context, name)
            assert actual_value == expected_value, "MISMATCH: actual({0}) == expected({1})".format(actual_value, expected_value)
        @then(u'the parameter "{name}" is none')
        def impl(context, name):
            actual_value = getattr(context, name, None)
            assert hasattr(context, name)
            assert actual_value is None, "MISMATCH: actual({0}) == None)".format(actual_value)
        def store_in_context(context, data):
            for name, value in data.items():
                setattr(context, name, value)
        use_step_matcher('re')
        @when(u'I try to match "(?P<foo>foo and more)"')
        def impl(context, **kwargs):
            kwargs["regexp_case"] = "simple"
            print("CASE UNNESTED: {0}".format(kwargs))
            store_in_context(context, kwargs)
        @when(u'I try to match "(?P<foo>foo(?P<bar>bar)?)"')
        def impl(context, **kwargs):
            kwargs["regexp_case"] = "nested"
            print("CASE NESTED: {0}".format(kwargs))
            store_in_context(context, kwargs)
        @when(u'I try to match "(?P<foo>foo) (?P<bar>bar)?"')
        def impl(context, **kwargs):
            kwargs["regexp_case"] = "optional"
            print("CASE OPTIONAL: {0}".format(kwargs))
            store_in_context(context, kwargs)
        """
    And   a file named "features/matching.feature" with:
        """
        Feature: Using regexp matcher with nested and optional parameters
            Scenario: regex, no nested groups, matching
                Given a simple regular expression "(?P<foo>foo and more)"
                When I try to match "foo and more"
                Then the parameter "regexp_case" is "simple"
                And  the parameter "foo" is "foo and more"
            Scenario: Nested groups without nested match
                Given a nested-group regular expression "(?P<foo>foo(?P<bar>bar)?)"
                When I try to match "foo"
                Then the parameter "regexp_case" is "nested"
                And  the parameter "foo" is "foo"
                And  the parameter "bar" is none
            Scenario: Nested groups with nested match
                Given a nested-group regular expression "(?P<foo>foo(?P<bar>bar)?)"
                When I try to match "foobar"
                Then the parameter "regexp_case" is "nested"
                And  the parameter "foo" is "foobar"
                And  the parameter "bar" is "bar"
            Scenario: Optional group without match
                Given a optional-group regular expression "(?P<foo>foo) (?P<bar>bar)?"
                When I try to match "foo "
                Then the parameter "regexp_case" is "optional"
                And  the parameter "foo" is "foo"
                And  the parameter "bar" is none
            Scenario: Optional group with match
                Given a optional-group regular expression "(?P<foo>foo) (?P<bar>bar)?"
                When I try to match "foo bar"
                Then the parameter "regexp_case" is "optional"
                And  the parameter "foo" is "foo"
                And  the parameter "bar" is "bar"
        """
  Scenario: Run regexp steps with --format=plain
    When I run "behave --format=plain features/matching.feature"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        5 scenarios passed, 0 failed, 0 skipped
        24 steps passed, 0 failed, 0 skipped, 0 undefined
        """
  Scenario: Run regexp steps with --format=pretty
    When I run "behave -c --format=pretty features/matching.feature"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        5 scenarios passed, 0 failed, 0 skipped
        24 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And  the command output should not contain
        """
        assert isinstance(text, unicode)
        """
    And  the command output should not contain
        """
        AssertationError
        """

@issue
Feature: Issue #92: Output from --format=plain shows skipped steps in next scenario

    . DUPLICATED, FIXED-BY: issue #35 solution.
    .
    . Given a feature has more than one scenario
    . When the --format=plain option is used
    .   and a middle step of a scenario fails
    . Then the skipped steps appear under the next scenario


  Scenario:
    Given a new working directory
    And   a file named "features/issue92_syndrome.feature" with:
        """
        Feature: Testing Plain Output
            Reproduces bug where output from previous scenario appears before current.
            Scenario: First example
                Given this step works
                When this step fails
                Then this step appears in the wrong place
            Scenario: Second example
                Given this step works
                When this step fails
                Then this step appears in the wrong place
        """
    And   a file named "features/steps/steps.py" with:
        """
        from behave import step
        @step(u'this step works')
        def working(context):
            pass
        @step(u'this step fails')
        def failing(context):
            assert False, 'step failed'
        @step(u'this step appears in the wrong place')
        def missing(context):
            pass
        """
    When I run "behave --no-timings --format=plain features/issue92_syndrome.feature"
    Then it should fail with:
        """
        0 features passed, 1 failed, 0 skipped
        0 scenarios passed, 2 failed, 0 skipped
        2 steps passed, 2 failed, 2 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature: Testing Plain Output
           Scenario: First example
               Given this step works ... passed
                When this step fails ... failed
           Assertion Failed: step failed
           Scenario: Second example
               Given this step works ... passed
                When this step fails ... failed
           Assertion Failed: step failed
        """

@issue
Feature: Issue #96: Sub-steps failed without any error info to help debug issue

    . I am trying to run execute_steps. One of them fails, but the error output
    . from behave has no details whatsoever. It is virtually impossible
    . to figure out why it failed. as no error output is present except the
    . final error message
    .
    .   def before_scenario(context,scenario):
    .       context.execute_steps(u'''
    .           When "admin:admin" sends POST "/tasks/testStart"
    .           Then I expect HTTP code 200
    .       ''')
    .
    . File ".../behave/runner.py", line 262, in execute_steps
    .  assert False, "FAILED SUB-STEP: %s" % step
    .  AssertionError: FAILED SUB-STEP: When "admin:admin" sends POST "/tasks/testStart"
    .
    .  All we get is the "sub-step failed" but no info whatsoever
    .  as to why it failed...
  Background:
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
        """
        from behave import step
        import sys
        @step(u'a step passes')
        def step_passes(context):
            pass

        @step(u'a step fails')
        def step_fails(context):
            assert False, 'EXPECT: Step fails.'

        @step(u'a step fails with stdout "{message}"')
        def step_fails_with_stdout(context, message):
            sys.stdout.write("%s\n" % message)
            assert False, 'EXPECT: Step fails with stdout.'

        @step(u'a step fails with stderr "{message}"')
        def step_fails_with_stderr(context, message):
            sys.stderr.write("%s\n" % message)
            assert False, 'EXPECT: Step fails with stderr.'

        @step(u'a step raises an error "{message}"')
        def step_raises_exception(context, message):
            raise RuntimeError(message)

        @step(u'the following steps should pass')
        def step_following_steps_should_pass(context):
            context.execute_steps(context.text.strip())
        """
  Scenario: Execute steps and one fails (EXPECTATION-MISMATCH: Assert fails)
    Given a file named "features/issue96_case1.feature" with:
        '''
        Feature:
            Scenario:
                When the following steps should pass:
                   """
                   Given a step passes
                   When  a step fails
                   Then  a step passes
                   """
        '''
    When I run "behave -c features/issue96_case1.feature"
    Then it should fail with:
        """
        Assertion Failed: FAILED SUB-STEP: When a step fails
        Substep info: Assertion Failed: EXPECT: Step fails.
        """
  Scenario: Execute steps and error occurs (UNEXPECTED: exception is raised)
    Given a file named "features/issue96_case2.feature" with:
        '''
        Feature:
            Scenario:
                When the following steps should pass:
                   """
                   Given a step passes
                   When a step raises an error "Alice is alive"
                   Then a step passes
                   """
        '''
    When I run "behave -c features/issue96_case2.feature"
    Then it should fail with:
        """
        RuntimeError: Alice is alive
        """
    And the command output should contain:
        """
        Assertion Failed: FAILED SUB-STEP: When a step raises an error "Alice is alive"
        Substep info: Traceback (most recent call last):
        """
  Scenario: Execute steps and one fails with stdout capture
    Given a file named "features/issue96_case3.feature" with:
        '''
        Feature:
            Scenario:
                When the following steps should pass:
                   """
                   Given a step passes
                   When a step fails with stdout "STDOUT: Alice is alive"
                   Then a step passes
                   """
        '''
    When I run "behave -c features/issue96_case3.feature"
    Then it should fail with:
        """
        Assertion Failed: FAILED SUB-STEP: When a step fails with stdout "STDOUT: Alice is alive"
        Substep info: Assertion Failed: EXPECT: Step fails with stdout.
        """
    And the command output should contain:
        """
        Captured stdout:
        STDOUT: Alice is alive
        """
  Scenario: Execute steps and one fails with stderr capture
    Given a file named "features/issue96_case4.feature" with:
        '''
        Feature:
            Scenario:
                When the following steps should pass:
                   """
                   Given a step passes
                   When a step fails with stderr "STDERR: Alice is alive"
                   Then a step passes
                   """
        '''
    When I run "behave -c features/issue96_case4.feature"
    Then it should fail with:
        """
        Assertion Failed: FAILED SUB-STEP: When a step fails with stderr "STDERR: Alice is alive"
        Substep info: Assertion Failed: EXPECT: Step fails with stderr.
        """
    And the command output should contain:
        """
        Captured stderr:
        STDERR: Alice is alive
        """
  Scenario: Execute steps and fail in before_scenario hook
    Given a file named "features/issue96_case5.feature" with:
        """
        Feature:
            Scenario:
                Given a step passes
                When  a step passes
                Then  a step passes
        """
    And a file named "features/environment.py" with:
        """
        def before_scenario(context, scenario):
            context.execute_steps(u'''
               Given a step passes
               When a step passes
               Then a step fails
            ''')
        """
    When I run "behave -c features/issue96_case5.feature"
    Then it should fail with:
        """
        HOOK-ERROR in before_scenario: AssertionError: FAILED SUB-STEP: Then a step fails
        Substep info: Assertion Failed: EXPECT: Step fails.
        """

@issue
Feature: Issue #99: Layout variation "a directory containing your feature files" is broken for running single features

    . When I use a layout as described in the 1.2.2 documentation,
    . I can only specify a whole directory of feature files to run.
    . Specifying a single feature file results in an error from behave:
    .
    .   $ behave -v tests/feature/webui/features/feature_under_test.feature
    .    ...
    .    Supplied path: "tests/feature/webui/features/feature_under_test.feature"
    .    Primary path is to a file so using its directory
    .    Trying base directory: .../tests/feature/webui/features
    .    Trying base directory: .../tests/feature/webui
    .    ERROR: Could not find "steps" directory in your specified path '.../tests/feature/webui/features'
    .    No steps directory in '.../tests/feature/webui/features'
    .
    . My directory layout is as follows:
    .
    .   .../tests/feature/webui/
    .       +-- features/
    .       +-- steps/
    .       +-- environment.py
    .
    . SEE ALSO:
    .   * http://packages.python.org/behave/gherkin.html#layout-variations


  Background:
    Given a new working directory
    And   a file named "root/steps/steps.py" with:
        """
        from behave import step
        @step(u'a step passes')
        def step_passes(context):
            pass
        """
    And   a file named "root/features/alice.feature" with:
        """
        Feature: Alice
          Scenario:
            Given a step passes
        """
    And   a file named "root/features/bob.feature" with:
        """
        Feature: Bob
          Scenario:
            Given a step passes
        """
    And   a file named "root/features2/charly.feature" with:
        """
        Feature: Charly
          Scenario:
            When a step passes
        """

  Scenario: Run features with root directory
    When I run "behave -f plain --no-timings root"
    Then it should pass with:
        """
        3 features passed, 0 failed, 0 skipped
        3 scenarios passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature: Alice
          Scenario:
            Given a step passes ... passed
        Feature: Bob
          Scenario:
            Given a step passes ... passed
        Feature: Charly
          Scenario:
            When a step passes ... passed
        """

  Scenario: Run features with root/features directory
    When I run "behave -f plain --no-timings root/features"
    Then it should pass with:
        """
        2 features passed, 0 failed, 0 skipped
        2 scenarios passed, 0 failed, 0 skipped
        2 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature: Alice
          Scenario:
            Given a step passes ... passed
        Feature: Bob
          Scenario:
            Given a step passes ... passed
        """

  Scenario: Run features with feature files
    When I run "behave -f plain --no-timings root/features/alice.feature root/features2/charly.feature"
    Then it should pass with:
        """
        2 features passed, 0 failed, 0 skipped
        2 scenarios passed, 0 failed, 0 skipped
        2 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature: Alice
          Scenario:
            Given a step passes ... passed
        Feature: Charly
          Scenario:
            When a step passes ... passed
        """

  Scenario: Run features with feature dir and feature files (other ordering)
    When I run "behave -f plain --no-timings root/features2 root/features/alice.feature"
    Then it should pass with:
        """
        2 features passed, 0 failed, 0 skipped
        2 scenarios passed, 0 failed, 0 skipped
        2 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature: Charly
          Scenario:
            When a step passes ... passed
        Feature: Alice
          Scenario:
            Given a step passes ... passed
        """

@issue
Feature: Issue #109: Insists that implemented tests are not implemented

    . STATUS: Resolved, not a behave problem.
    .
    . Following feature file marks implemented step "when I submit the following data"
    . as not implemented.


  Scenario:
    Given a new working directory
    And   a file named "features/syndrome109.feature" with:
        """
        @wip
        Feature: Manage accounts from the admin interface
            Scenario: Login successfully via login form
                Given I navigate to "/admin/"
                when I submit the following data
                    | name          | value         |
                    | username      | admin@foo.bar |
                    | password      | pass          |
                then I see the word "Welcome"
            Scenario: Create user via admin user creation form
                Given I navigate to "/admin/users/user/add/"
                when I submit the following data
                    | name           | value                           |
                    | email          | spaaaaaaaaaaaaaaaaaaam@ham.eggs |
                    | password1      | pass                            |
                    | password2      | pass                            |
                then I see the word "successfully"
        """
    And   a file named "features/steps/steps.py" with:
        """
        from behave import given, when, then
        @given(u'I navigate to "{url}"')
        def step_navigate_to_url(context, url):
            pass
        @when(u'I submit the following data')
        def step_submit_data(context):
            pass
        @then(u'I see the word "{word}"')
        def step_see_word(context, word):
            pass
        """
    When I run "behave -w features/syndrome109.feature"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        2 scenarios passed, 0 failed, 0 skipped
        6 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should not contain:
        """
        You can implement step definitions for undefined steps with these snippets:
        """

@issue
Feature: Issue #111: Comment following @wip tag results in scenario being ignored

    . If a comment is placed after the @wip tag, the following scenario
    . is ignored by behave:
    .
    .   @wip # comment: this is work in progress
    .   Scenario: test scenario
    .
    . results in behave -w not running the "test scenario".
    . After removing the comment, it runs as expected.


  Scenario: Test Setup
    Given a new working directory
    And   a file named "features/steps/passing_steps.py" with:
        """
        from behave import step
        @step(u'a step passes')
        def step_passes(context):
            pass
        """
    And   a file named "features/syndrome111.feature" with:
        """
        Feature:
          @wip  # Comment: blabla
          Scenario: S1
            Given a step passes
          @wip  @one    # Comment: foobar
          Scenario: S2
            Given a step passes
        """

  Scenario: Scenario w/ comment on tag-line should run as normal
    When I run "behave --wip features/syndrome111.feature"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        2 scenarios passed, 0 failed, 0 skipped
        2 steps passed, 0 failed, 0 skipped, 0 undefined
        """

  Scenario: Ensure 2nd scenario can be selected with other tag
    When I run "behave -f plain --tags=one features/syndrome111.feature"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        1 scenario passed, 0 failed, 1 skipped
        1 step passed, 0 failed, 1 skipped, 0 undefined
        """

@issue
@change_request
Feature: Issue #112: Improvement to AmbiguousStep error

    . AmbiguousStep could be more useful if it also showed the existing string
    . with which the new one is clashing. This is particularly useful
    . if using step parameters.


  Background:
    Given a new working directory
    And   a file named "features/syndrome112.feature" with:
        """
        Feature:
          Scenario:
            Given I buy 10 oranges
        """

  Scenario: Good step ordering -- From specific to generic regular expression
    Given a file named "features/steps/good_steps.py" with:
        """
        from behave import given, when, then
        # -- ORDERING-IMPORTANT: From more specific steps to less specific.
        @given(u'I buy {number:n} {items:w}')
        def step_given_I_buy2(context, number, items):
            pass
        # -- OTHERWISE: Generic step matches all other patterns.
        @given(u'I buy {amount} {product}')
        def step_given_I_buy(context, amount, product):
            pass
        """
    When I run "behave -c features/syndrome112.feature"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        1 scenario passed, 0 failed, 0 skipped
        1 step passed, 0 failed, 0 skipped, 0 undefined
        """


  Scenario: Bad step ordering causes AmbiguousStep
    Given a file named "features/steps/bad_steps.py" with:
        """
        from behave import given, when, then
        # -- ORDERING-VIOLATED: Generic step comes first.
        @given(u'I buy {amount} {product}')
        def step_given_I_buy(context, amount, product):
            pass
        # -- AMBIGUOUS-STEP: Will occur here.
        @given(u'I buy {number:n} {items:w}')
        def step_given_I_buy2(context, number, items):
            pass
        """
    When I run "behave -c features/syndrome112.feature"
    Then it should fail
    And the command output should contain:
        """
        AmbiguousStep: @given('I buy {number:n} {items:w}') has already been defined in
          existing step @given('I buy {amount} {product}') at features/steps/bad_steps.py:4
        """

@issue
@change_request
Feature: Issue #114: Avoid unnecessary blank lines w/ --no-skipped option

    . Unnessary blank lines appear when you use (for each skipped feature):
    .
    .    behave -f progress --tags=@one --no-skipped ...

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And   a file named "features/steps/passing_steps.py" with:
        """
        from behave import step
        @step(u'a step passes')
        def step_passes(context):
            pass
        """
    And   a file named "features/e1.feature" with:
        """
        @example
        Feature: E1
          Scenario: S1.1
            Given a step passes
        """
    And   a file named "features/e2.feature" with:
        """
        @exclude
        Feature: E2
          Scenario: S2.1
            Given a step passes
        """
    And   a file named "features/e3.feature" with:
        """
        @example
        Feature: E3
          Scenario: S3.1
            Given a step passes
        """

  Scenario: Run Features with tags and --show-skipped option
    When I run "behave -f progress --tags=@example"
    Then it should pass with:
        """
        2 features passed, 0 failed, 1 skipped
        2 scenarios passed, 0 failed, 1 skipped
        2 steps passed, 0 failed, 1 skipped, 0 undefined
        """
    And the command output should contain:
        """
        features/e1.feature  .
        features/e2.feature  S
        features/e3.feature  .
        """

  Scenario: Run Features with tag and --no-skipped option (CASE 1)
    When I run "behave -f progress --tags=@example --no-skipped"
    Then it should pass with:
        """
        2 features passed, 0 failed, 1 skipped
        2 scenarios passed, 0 failed, 1 skipped
        2 steps passed, 0 failed, 1 skipped, 0 undefined
        """
    And the command output should contain exactly:
        """
        features/e1.feature  .
        features/e3.feature  .
        """
    But the command output should not contain exactly:
        """
        features/e1.feature  .
        features/e3.feature  .
        """

  Scenario: Run Features with other tag and --no-skipped option (CASE 2)
    When I run "behave -f progress --tags=@exclude --no-skipped"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 2 skipped
        1 scenario passed, 0 failed, 2 skipped
        1 step passed, 0 failed, 2 skipped, 0 undefined
        """
    And the command output should contain exactly:
        """
        features/e2.feature  .
        """

  Scenario: Run Features with tag, --no-skipped and plain formatter (CASE 3)
    When I run "behave -f plain --tags=@example --no-skipped -T"
    Then it should pass with:
        """
        2 features passed, 0 failed, 1 skipped
        2 scenarios passed, 0 failed, 1 skipped
        2 steps passed, 0 failed, 1 skipped, 0 undefined
        """
    And the command output should contain exactly:
        """
        Feature: E1
          Scenario: S1.1
            Given a step passes ... passed
        Feature: E3
        """
    But the command output should not contain exactly:
        """
        Feature: E1
          Scenario: S1.1
            Given a step passes ... passed
        Feature: E3
        """

@issue
@change_request
Feature: Issue #116: SummaryReporter shows failed scenarios list

  Scenario: Test Setup
    Given a new working directory
    And   a file named "features/steps/passing_failing_steps.py" with:
        """
        from behave import step
        @step(u'a step passes')
        def step_passes(context):
            pass
        @step(u'a step fails')
        def step_fails(context):
            assert False, "FAILS"
        """
    And   a file named "features/e1.feature" with:
        """
        Feature: E1
          Scenario: E1.1
            Given a step passes
          @xfail
          Scenario: E1.2 (XFAIL)
            Given a step fails
          Scenario: E1.3
            Given a step passes
        """
    And   a file named "features/e2.feature" with:
        """
        @example2
        Feature: E2
          @xfail
          Scenario: E2.1 (XFAIL)
            Given a step fails
          Scenario: E2.2
            Given a step passes
        """

  Scenario: Summary shows list of failed scenarios when at least one fails
    When I run "behave -f plain features/"
    Then it should fail
    And the command output should contain:
        """
        Failing scenarios:
          features/e1.feature:7  E1.2 (XFAIL)
          features/e2.feature:5  E2.1 (XFAIL)
        0 features passed, 2 failed, 0 skipped
        3 scenarios passed, 2 failed, 0 skipped
        3 steps passed, 2 failed, 0 skipped, 0 undefined
        """

  Scenario: Summary hides list of failed scenarios when all scenarios pass
    When I run "behave -f plain --tags=~@xfail features/"
    Then it should pass with:
        """
        2 features passed, 0 failed, 0 skipped
        3 scenarios passed, 0 failed, 2 skipped
        3 steps passed, 0 failed, 2 skipped, 0 undefined
        """
    But the command output should not contain:
        """
        Failing scenarios:
        """
@issue
Feature: Issue #125: Duplicate "Captured stdout" if substep has failed


  Background: Test Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      from behave import step
      @step('a step fails with stdout "{message}"')
      def step_fails_with_stdout(context, message):
          print(message)
          assert False, 'EXPECT: Step fails with stdout.'
      @step('substep fails with stdout "{message}"')
      def substep_fails_with_stdout(context, message):
          context.execute_steps(u'When a step fails with stdout "%s"' % message)
      """

  Scenario: Subprocess call shows generated output
    Given a file named "features/issue125_example.feature" with:
      """
      Feature:
          Scenario:
              When substep fails with stdout "Hello"
      """
    When I run "behave -f plain --no-timings features/issue125_example.feature"
    Then it should fail with:
      """
      0 scenarios passed, 1 failed, 0 skipped
      0 steps passed, 1 failed, 0 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Feature:
          Scenario:
              When substep fails with stdout "Hello" ... failed
      Assertion Failed: FAILED SUB-STEP: When a step fails with stdout "Hello"
      Substep info: Assertion Failed: EXPECT: Step fails with stdout.
      """
    And the command output should contain 1 times:
      """
      Captured stdout:
      Hello
      """
    But note that "the captured output should not be contained multiple times"

@issue
Feature: Issue #127: Strip trailing colons

  . Trailing colon in a step is stripped by the Gherkin parser.
  . Undefined step snippets should not suggest the step with a trailing colon.
  .
  . GENERAL RULE (by looking at the parser):
  .   1. Colon in step in feature file is OK
  .      (parser strips this for step-with-table or step-with-multiline-text).
  .   2. Step definitions in Python files should not end with a colon
  .      (used in @given/@when/@then decorators).


  Background:
    Given a new working directory
    And   a file named "features/example127.feature" with:
        """
        Feature:
          Scenario:
            Given the following superusers exist:
              | Name  | User Id |
              | Alice | 101     |
              | Bob   | 102     |
        """

  Scenario: Step Definition has no trailing colon (GOOD CASE)
    Given a file named "features/steps/good_steps.py" with:
        """
        from behave import given
        @given(u'the following superusers exist')
        def step_given_following_superusers_exist(context):
            pass
        """
    When I run "behave -f plain features/example127.feature"
    Then it should pass
    And the command output should not contain:
        """
        You can implement step definitions for undefined steps with these snippets:
        @given(u'the following superusers exist:')
        def step_impl(context):
            raise NotImplementedError(u'STEP: Given the following superusers exist:')
        """

  Scenario: Step Definition has trailing colon (BAD CASE)
    Given a file named "features/steps/bad_steps.py" with:
        """
        from behave import given
        @given(u'the following superusers exist:')
        def step_given_following_superusers_exist(context):
            pass
        """
    When I run "behave -f plain features/example127.feature"
    Then it should fail
    And the command output should contain:
        """
        You can implement step definitions for undefined steps with these snippets:
        @given(u'the following superusers exist')
        def step_impl(context):
            raise NotImplementedError(u'STEP: Given the following superusers exist')
        """
@issue
@not_reproducible
Feature: Issue #139: Wrong steps seem to be executed when using --wip

  . RELATED-TO: issue #35
  . behave --format=plain --tags @one" seems to execute right scenario w/ wrong steps
  .
  . If you have a feature file with two scenarios where the second is tagged
  . with @wip, running behave -w will output step names from the first scenario.
  . It does seem to run the correct code for the steps.


  Scenario:
    Given a new working directory
    And a file named "features/steps/steps.py" with:
        """
        from behave import given, when, then, step
        @step('a step passes')
        def step_passes(context):
            pass
        @step('a step fails')
        def step_fails(context):
            assert False, "XFAIL"
        @when('I run a test step')
        def step_impl(context):
            pass
        @when('I run some other test step')
        def step_impl(context):
            pass
        @then('I should not see a failure here')
        def step_impl(context):
            pass
        """
    And a file named "features/issue0139_example.feature" with:
        """
        Feature: Bug in wip/behave -w
            Scenario: This is strange
                Given a step passes
                When a step passes
                Then a step fails
            @wip
            Scenario: Demonstrate bug
                When I run a test step
                And I run some other test step
                Then I should not see a failure here
        """
    When I run "behave -w -f plain -T features/issue0139_example.feature"
    Then it should pass
    And the command output should contain:
        """
        Feature: Bug in wip/behave -w
          Scenario: This is strange
          Scenario: Demonstrate bug
            When I run a test step ... passed
            And I run some other test step ... passed
            Then I should not see a failure here ... passed
        """

@issue
@not_reproducible
Feature: Issue #142: --junit flag fails to output with step table data: TypeError: <Row [u'data', u'value']> is not JSON serializable

      DUPLICATES: issue #67 (already fixed).

  Scenario:
    Given a new working directory
    And a file named "features/steps/steps.py" with:
        """
        from behave import given, when, then, step
        @then('use table data with')
        def step_impl(context):
            pass
        """
    And a file named "features/issue0142_example.feature" with:
        """
        Feature:
            Scenario: Use a table
             Then use table data with:
                 | data                             | value |
                 | behave outputs junit with tables | false |
        """
    When I run "behave --junit -f json features/issue0142_example.feature"
    Then it should pass
    But the command output should not contain:
        """
        TypeError: <Row [u'behave outputs junit with tables', u'false']> is not JSON serializable
        """
    And the command output should not contain:
        """
        Traceback (most recent call last):
        """

@issue
Feature: Issue #143: Logging starts with a StreamHandler way too early

  . This verifies that some imported library or other item has not made a
  . call to logging too soon, which would add a StreamHandler.


  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
        """
        import logging
        from behave import given, when, then, step
        @step('I create {count:n} log records')
        def step_create_log_records(context, count):
            for i in range(count):
                logging.debug('Some debug logging')
        """
    And a file named "features/issue0143_example.feature" with:
        """
        Feature: Logging should not be output unless there is a failure
            Scenario: A passing test
                Given I create 4 log records
        """

  Scenario: Ensure that no log-ouput occurs with enabled log-capture
    Given an empty file named "features/environment.py"
    When I run "behave -f plain --logcapture features/issue0143_example.feature"
    Then it should pass
    And the command output should not contain:
        """
        DEBUG:root:Some debug logging
        """


  Scenario: Ensure that log-ouput occurs with disabled log-capture
    Given a file named "features/environment.py" with:
        """
        import logging
        def before_all(context):
            # -- basicConfig() will not set level if setup is already done.
            logging.basicConfig()
            logging.getLogger().setLevel(logging.DEBUG)
        """
    When I run "behave -f plain --no-logcapture features/issue0143_example.feature"
    Then it should pass
    And the command output should contain:
        """
        DEBUG:root:Some debug logging
        """
@issue
Feature: Issue #145: before_feature/after_feature should not be skipped

  Hooks before_feature(), after_feature() (and before_step()) are skipped
  if --tags options select feature tag and scenario tag.

  SEE ALSO: https://github.com/cucumber/cucumber/wiki/Tags

  @setup
  Scenario: Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
        """
        from behave import step
        @step('a step passes')
        def step_passes(context):
            pass
        """
    And a file named "features/issue0145_example.feature" with:
        """
        @feature
        Feature: Feature-145
          @scenario
          Scenario: Scenario-145
            Given a step passes
            When a step passes
            Then a step passes
        """
    And a file named "features/environment.py" with:
        """
        from __future__ import print_function
        def before_feature(context, feature):
            print("hooks.before_feature: %s called." % feature.name)
        def after_feature(context, feature):
            print("hooks.after_feature: %s called." % feature.name)
        """

  Scenario: Select only @scenario tag
    When I run "behave -f plain -T --tags=@scenario features/issue0145_example.feature"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the behave hook "before_feature" was called
    And the behave hook "after_feature" was called

  Scenario: Select @feature tag and @scenario tag (logical-and, fails if not fixed)
    When I run "behave -f plain -T --tags=@feature --tags=@scenario features/issue0145_example.feature"
    Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        1 scenario passed, 0 failed, 0 skipped
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the behave hook "before_feature" was called
    And the behave hook "after_feature" was called

@issue
@already_fixed
Feature: Issue #148: Substeps do not fail

  FIXED-BY: issue #117 context.execute_steps() should support table and multi-line text.
  RELATED-TO: issue #96

  @setup
  Scenario: Setup
    Given a new working directory
    And a file named "features/steps/passing_steps.py" with:
        """
        @step('a step passes')
        def step_passes(context):
            pass
        @step('a step fails')
        def step_fails(context):
            assert False, "XFAIL"
        """
    And a file named "features/issue0148_example.feature" with:
        """
        Feature: Sub steps
          @xfail
          Scenario: Failing test without substeps
            Given a step passes
            When a step fails
            Then a step passes
          @xfail
          Scenario: Failing test with substeps
            Given a step passes
            When I do something with stupid substeps
            Then a step passes
        """

  Scenario: Missing Step Keywords in Substeps
    Given a file named "features/steps/substeps.py" with:
        """
        @When('I do something with stupid substeps')
        def step(context):
            context.execute_steps(u'''
                I do something stupid
                there is a second stupid step
            ''')  # Given/When/Then keywords are missing in substeps above.
        """
    When I run "behave -f plain -T features/issue0148_example.feature"
    Then it should fail with:
        """
        0 features passed, 1 failed, 0 skipped
        0 scenarios passed, 2 failed, 0 skipped
        2 steps passed, 2 failed, 2 skipped, 0 undefined
        """
    And the command output should contain:
        """
          Scenario: Failing test without substeps
            Given a step passes ... passed
            When a step fails ... failed
        """
    And the command output should contain:
        """
          Scenario: Failing test with substeps
            Given a step passes ... passed
            When I do something with stupid substeps ... failed
        """
    And the command output should contain:
        """
        ParserError: Failed to parse <string>:
        Parser failure in state steps, at line 2: "I do something stupid"
        """


  Scenario: Use Step Keywords in Substeps
    Given a file named "features/steps/substeps.py" with:
        """
        @when('I do something with stupid substeps')
        def step(context):
            context.execute_steps(u'''
                When a step fails
                Then a step fails
            ''')
        """
    When I run "behave -f plain -T features/issue0148_example.feature"
    Then it should fail with:
        """
        0 features passed, 1 failed, 0 skipped
        0 scenarios passed, 2 failed, 0 skipped
        2 steps passed, 2 failed, 2 skipped, 0 undefined
        """
    And the command output should contain:
        """
          Scenario: Failing test with substeps
            Given a step passes ... passed
            When I do something with stupid substeps ... failed
            Assertion Failed: FAILED SUB-STEP: When a step fails
            Substep info: Assertion Failed: XFAIL
        """
    But the command output should not contain:
        """
        ParserError: Failed to parse <string>
        """

@issue
Feature: Issue #152: Fix encoding issues

  . I fixed two encoding issues in pretty formatter and in JUnit serialization.
  . Now it's possible to use accented letters in feature files and
  . create JUnit reports from the tests.


  Scenario: Ensure JUnit reports can be created from a foreign language
    Given a new working directory
    And an empty file named "features/steps/steps.py"
    And a file named "features/eins.feature" with:
        """
        # language: de
        Funktionalitt: Die Welt ist schn
            Szenario: Was wre wenn die schne, neue Welt untergeht
        """
    When I run "behave -f plain --junit --no-timings features/eins.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      0 steps passed, 0 failed, 0 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Funktionalitt: Die Welt ist schn
         Szenario: Was wre wenn die schne, neue Welt untergeht
      """


  @reuse.colocated_test
  Scenario: Ensure JUnit reports can be created from a foreign language
    Given I use the current directory as working directory
    When I run "behave -f plain --junit --no-timings tools/test-features/french.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      2 scenarios passed, 0 failed, 0 skipped
      5 steps passed, 0 failed, 0 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Fonctionnalit: testing stuff
         Scnario: test stuff
           Etant donn I am testing stuff ... passed
           Quand I exercise it work ... passed
           Alors it will work ... passed
         Scnario: test more stuff
            Etant donn I am testing stuff ... passed
            Alors it will work ... passed
      """
@issue
Feature: Issue #159: output stream is wrapped twice in the codecs.StreamWriter

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And   a file named "features/steps/steps.py" with:
      """
      # -*- coding: utf-8 -*-
      from behave import step
      @step('firstname is "{name}"')
      def step_impl(context, name):
          pass
      @step(u'full name is Loc "{name}"')
      def step_impl(context, name):
          pass
      """

  Scenario: Single feature, pass (a)
    Given a file named "features/issue159_stream_writer.feature" with:
      """
      Feature:
        Scenario:
          When firstname is "Loc"
      """
    When I run "behave -f plain features/"
    Then it should pass


  Scenario: Single feature, pass (b)
    Given a file named "features/issue159_stream_writer.feature" with:
      """
      Feature:
        Scenario:
          When full name is Loc "Dupont"
      """
    When I run "behave -f plain features/"
    Then it should pass


  Scenario: Two features, FAIL (a)
    Given a file named "features/issue159_stream_writer.feature" with:
      """
      Feature:
        Scenario:
          When full name is Loc "Dupont"
      """
    And   a file named "features/issue159_stream_writer_again.feature" with:
      """
      Feature:
        Scenario:
          When full name is Loc "Dupond"
      """
    When I run "behave -f plain features/"
    Then it should pass


  Scenario: Two features, FAIL (b)
    Given a file named "features/issue159_stream_writer.feature" with:
      """
      Feature:
        Scenario:
          When firstname is "Loc"
      """
    And   a file named "features/issue159_stream_writer_again.feature" with:
      """
      Feature:
        Scenario:
          When firstname is "Loc"
      """
    When I run "behave -f plain features/"
    Then it should pass
@issue
Feature: Issue #162 Unnecessary ContextMaskWarnings when assert fails or exception is raised

  . Behave shows unnecessary ContextMaskWarnings related to:
  .
  .   * tags
  .   * capture_stdout
  .   * capture_stderr
  .   * log_capture
  .
  . if:
  .
  .   * an assertion fails in a step-definition/step-function
  .   * an exception is raised by a step-definition/step-function
  .
  . and an additional scenario follows.
  . REASON: Context "behave" mode is not restored when an exception is raised.


  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
      """
      from behave import step
      @step('a step passes')
      def step_passes(context):
          pass
      @step('a step assert fails')
      def step_assert_fails(context):
          assert False, "XFAIL-STEP"
      @step('an exception is raised')
      def step_raises_exception(context):
          raise RuntimeError("XFAIL-STEP")
      """


  Scenario: Assertion fails in a step
    Given a file named "features/example0162_assert_fails.feature" with:
      """
      Feature:
        Scenario:
          Given a step passes
          When a step assert fails
          Then a step passes
        Scenario:
          Given a step passes
      """
    When I run "behave -f plain features/example0162_assert_fails.feature"
    Then it should fail with:
      """
      1 scenario passed, 1 failed, 0 skipped
      2 steps passed, 1 failed, 1 skipped, 0 undefined
      """
    But the command output should not contain:
      """
      ContextMaskWarning: user code is masking context attribute
      """


  Scenario: Exception is raised in a step
    Given a file named "features/example0162_exception_raised.feature" with:
      """
      Feature:
        Scenario:
          Given a step passes
          When an exception is raised
          Then a step passes
        Scenario:
          Given a step passes
      """
    When I run "behave -f plain features/example0162_exception_raised.feature"
    Then it should fail with:
      """
      1 scenario passed, 1 failed, 0 skipped
      2 steps passed, 1 failed, 1 skipped, 0 undefined
      """
    But the command output should not contain:
      """
      ContextMaskWarning: user code is masking context attribute
      """
@issue
Feature: Issue #171: Importing step from other step file fails with AmbiguousStep Error

  . When a step module imports another step module
  . this should not cause AmbiguousStep errors
  . due to duplicated registration of the same step functions.
  .
  . NOTES:
  .   * In general you should avoid this case (provided as example here).


  @reuse.colocated_test
  Scenario: Step module imports other step module
    Given I use the current directory as working directory
    When I run "behave -f plain features/step.import_other_step_module.feature"
    Then it should pass
@issue
Feature: Issue #172 Junit report file name populated incorrectly when running against a feature file

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
      """
      from behave import step
      @step('a step passes')
      def step_passes(context):
          pass
      """
    And a file named "features/feature_in_root_folder.feature" with:
      """
      Feature:
        Scenario:
          Given a step passes
      """
    And a file named "features/subfolder/feature_in_subfolder.feature" with:
      """
      Feature:
        Scenario:
          Given a step passes
      """

  Scenario: Running behave for one feature in root folder
    When I run "behave --junit --junit-directory=test_results features/feature_in_root_folder.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      """
    And a file named "test_results/TESTS-feature_in_root_folder.xml" exists

  Scenario: Running behave for one feature in a subfolder
    When I run "behave --junit --junit-directory=test_results features/subfolder/feature_in_subfolder.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      """
    And a file named "test_results/TESTS-subfolder.feature_in_subfolder.xml" exists

  Scenario: Running behave for all features
    When I run "behave --junit --junit-directory=test_results"
    Then it should pass with:
      """
      2 features passed, 0 failed, 0 skipped
      """
    And a file named "test_results/TESTS-feature_in_root_folder.xml" exists
    And a file named "test_results/TESTS-subfolder.feature_in_subfolder.xml" exists
@issue
Feature: Issue #175: Scenario isn't marked as 'failed' when Background step fails

  Scenario has currently status "skipped" when a background step fails.
  Expected is that scenario status should be "failed".
  Ensure that this is the case.

  RELATED: features/background.feature
  REUSE:   Scenario from there (as copy).

  . NOTE:
  .     Cucumber has a slightly different behaviour.
  .     When a background step fails the first scenario is marked as failed.
  .     But the remaining scenarios are marked as skipped.
  .
  .     This can lead to problems when you have sporadic background step failures.
  .     For this reason, behave retries the background steps for each scenario.
  .
  . SEE ALSO:
  .   * https://github.com/cucumber/cucumber/blob/master/features/docs/gherkin/background.feature


  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/background_steps.py" with:
        """
        from behave import step
        @step('{word} background step {outcome}')
        def step_background_step_passes_or_fails(context, word, outcome):
            if outcome == "fails":
                assert False, "XFAIL: background step"
            elif outcome == "passes":
                pass
            else:
                message = "Unexpected outcome=%s. Use: passes, fails"
                raise RuntimeError(message % outcome)
        """
    And a file named "features/steps/passing_steps.py" with:
        """
        from behave import step
        @step('{word} step passes')
        def step_passes(context, word):
            pass
        @step('{word} step fails')
        def step_passes(context, word):
            assert False, "XFAIL"
        """


  Scenario: Failing Background Step causes all Scenarios to fail
    Given a file named "features/example.background_step_fails.feature" with:
        """
        Feature:
          Background: B1
            Given a background step passes
            And a background step fails
            And another background step passes
          Scenario: S1
            When a step passes
          Scenario: S2
            Then a step passes
            And another step passes
        """
    When I run "behave -f plain -T features/example.background_step_fails.feature"
    Then it should fail with:
        """
        0 scenarios passed, 2 failed, 0 skipped
        2 steps passed, 2 failed, 5 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature:
          Background: B1
          Scenario: S1
            Given a background step passes ... passed
            And a background step fails ... failed
        Assertion Failed: XFAIL: background step
          Scenario: S2
            Given a background step passes ... passed
            And a background step fails ... failed
        Assertion Failed: XFAIL: background step
        """
@issue
Feature: Issue #177: Cannot setup logging_format
  
  . DESCPRIPTION:
  .   When the logging_format is set in the behave configuration file
  .   or on command-line, an exception is thrown, because
  .   the ConfigParser tries to replace the placeholders in the format string
  .   with option values in the configuration file (which do not exist).
  .
  . SOLUTION:
  .   The format string must be processed as raw value (by the ConfigParser).
  .
  . RELATED:
  .   * features/logging.setup_format.feature
  .   * features/logging.setup_level.feature


  @reuse.colocated_test
  Scenario: Setup logging_format
    Given I use the current directory as working directory
    When I run "behave -f plain features/logging.setup_format.feature"
    Then it should pass
    And the command output should not contain:
      """
      Traceback (most recent call last):
      """
    And the command output should not contain:
      """
      ConfigParser.InterpolationMissingOptionError: Bad value
      """

  @reuse.colocated_test
  Scenario: Setup logging_level

    Ensure that the problem that was also mentioned, works as expected.
    Note that this "problem" never existed (hint: missing user knowledge).

    Given I use the current directory as working directory
    When I run "behave -f plain features/logging.setup_level.feature"
    Then it should pass
@issue
Feature: Issue #181: Escape apostrophes in undefined steps snippets

  . I have noticed that, for the following line in my features file:
  .
  .   Then I'm redirected to http://www.example.com
  .
  . Behave outputs the following:
  .
  .   @then(u'I'm redirected to http://www.example.com')
  .   def step_impl(context):
  .       assert False


  Scenario:
    Given a new working directory
    And an empty file named "features/steps/steps.py"
    And a file named "features/issue181_example.feature" with
        """
        Feature:
          Scenario:
            Given I'm using an "undefined step"
        """
    When I run "behave -f plain features/issue181_example.feature"
    Then it should fail with:
        """
        0 steps passed, 0 failed, 0 skipped, 1 undefined
        """
    And the command output should contain:
        """
        You can implement step definitions for undefined steps with these snippets:
        @given(u'I\'m using an "undefined step"')
        def step_impl(context):
            raise NotImplementedError(u'STEP: Given I\'m using an "undefined step"')
        """
@issue
Feature: Issue #184: TypeError when running behave with --include option

  . Running behave with option '--include' causes fail with following error:
  .
  .  Traceback (most recent call last):
  .   File "/.../bin/behave", line 8, in
  .     load_entry_point('behave==1.2.3', 'console_scripts', 'behave')()
  .   File "/.../lib/python2.7/site-packages/behave/__main__.py", line 111, in main
  .   ...
  .   File "/.../lib/python2.7/site-packages/behave/runner.py", line 490, in run_with_paths
  .     if not self.config.exclude(filename) ]
  .   File "/.../lib/python2.7/site-packages/behave/configuration.py", line 488, in exclude
  .     if self.include_re and self.include_re.search(filename) is None:
  .   TypeError: expected string or buffer
  .
  . RELATED:
  .  * features/runner.select_files_by_regexp.feature
  .  * features/runner.select_files_by_regexp2.feature

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/passing_steps.py" with:
      """
      from behave import step
      @step('{word:w} step passes')
      def step_passes(context, word):
          pass
      """
    And a file named "features/alice.feature" with:
      """
      Feature: Alice
        Scenario: A1
          Given a step passes
      """
    And a file named "features/bob.feature" with:
      """
      Feature: Bob
        Scenario: B1
          When another step passes
        Scenario: B2
          Then another step passes
      """

  Scenario: Use --include command-line option to select some features
    When I run "behave -f plain --include='features/a.*\.feature'"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      """
    And the command output should contain:
      """
      Feature: Alice
      """
    But the command output should not contain:
      """
      Feature: Bob
      """


  Scenario: Use --include command-line option to select all features
    When I run "behave -f plain --include='.*\.feature'"
    Then it should pass with:
      """
      2 features passed, 0 failed, 0 skipped
      3 scenarios passed, 0 failed, 0 skipped
      """


  Scenario: Use --exclude command-line option
    When I run "behave -f plain --exclude='features/a.*\.feature'"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      2 scenarios passed, 0 failed, 0 skipped
      """
    And the command output should contain:
      """
      Feature: Bob
      """
    But the command output should not contain:
      """
      Feature: Alice
      """


  Scenario: Use --include and --exclude command-line options
    When I run "behave -f plain --include='.*\.feature' --exclude='features/a.*\.feature'"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      2 scenarios passed, 0 failed, 0 skipped
      """
    And the command output should contain:
      """
      Feature: Bob
      """
    But the command output should not contain:
      """
      Feature: Alice
      """

  Scenario: Use --include command-line option with file location
    When I run "behave -f plain --include='features/a.*\.feature' features/alice.feature:3"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      """
    And the command output should contain:
      """
      Feature: Alice
      """
    But the command output should not contain:
      """
      Feature: Bob
      """

  Scenario: Use --exclude command-line option with feature list file
    Given a file named "selected.txt" with:
      """
      # -- FEATURE-LIST FILE:
      features/alice.feature:3
      features/bob.feature:7
      """
    When I run "behave -f plain --no-skipped --exclude='.*/a.*\.feature' @selected.txt"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 1 skipped
      """
    And the command output should contain:
      """
      Feature: Bob
        Scenario: B2
      """
    But the command output should not contain:
      """
      Feature: Alice
@issue
Feature: Issue #186: ScenarioOutline uses wrong return value when if fails

  ScenarioOutline returns encountered a failure only if the last scenario failed.
  Failures in earlier examples return the wrong result.
  Ensure that ScenarioOutline run-logic behaves as expected.

  @reuse.colocated_test
  Scenario: Reuse existing test
    Given I use the current directory as working directory
    When I run "behave -f plain features/scenario_outline.basics.feature"
    Then it should pass
@issue
Feature: Issue #188: Better diagnostics if nested step is undefined
  
  . Currently if nested step has no match, it's shown like this:
  .
  .     Assertion Failed: Sub-step failed: When I do strange thign
  .     Substep info: None
  .
  . Took some time to find that typo.
  . The suggestion is to fill substep error_message with at least "No match for step"
  . so it would become:
  .
  .     Assertion Failed: Sub-step failed: When I do strange thign
  .     Substep info: No match for step
  .
  . IMPLEMENTATION NOTE:
  . A slightly different output is provided:
  .
  .     Assertion Failed: UNDEFINED SUB-STEP: When I do strange thign


  Scenario: Nested steps contain an undefined step
    Given a new working directory
    And a file named "features/steps/steps.py" with:
      """
      from behave import step
      @step('{word:w} step passes')
      def step_passes(context, word):
          pass
      @then('a good diagnostic message is shown')
      def step_good_diagnostic_message_is_shown(context):
          pass
      @step('I execute nested steps with an undefined step')
      def step_passes(context):
          context.execute_steps(u'''
            Given another step passes
            When an undefined, nested step is executed
            Then third step passes
          ''')
      """
    And a file named "features/example.execute_nested_undefined_step.feature" with:
      """
      Feature:
        Scenario:
          Given a step passes
          When I execute nested steps with an undefined step
          Then a good diagnostic message is shown
      """
    When I run "behave -f plain -T features/example.execute_nested_undefined_step.feature"
    Then it should fail with:
      """
      Scenario:
        Given a step passes ... passed
        When I execute nested steps with an undefined step ... failed
      Assertion Failed: UNDEFINED SUB-STEP: When an undefined, nested step is executed
      """
@issue
Feature: Issue #191 Using context.execute_steps() may change context.table/.text

  . PROBLEM DESCRIPTION:
  . When you execute nested steps via "context.execute_steps()" in a
  . step implementation, the following context attributes of the current step
  . may be modified and may be longer valid:
  .   * context.text (multi-line text)
  .   * context.table


  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/common_steps.py" with:
        """
        from behave import given, step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        @given('I define the following nested steps')
        def step_define_nested_steps(context):
            assert context.text is not None, "REQUIRE: text"
            context.nested_steps = context.text
        """
    And a file named "features/steps/table_steps.py" with:
        """
        from behave import when, then, step
        @step('I use another table with')
        def step_use_another_table_with(context):
            assert context.table, "REQUIRE: table"
            context.nested_table = context.table
        @when('I execute the nested steps and use the table')
        def step_execute_nested_steps_and_use_table(context):
            assert context.table, "REQUIRE: table"
            assert context.nested_steps, "REQUIRE: context.nested_steps"
            context.my_table1 = context.table
            context.execute_steps(context.nested_steps)
            context.my_table2 = context.table
        @then('the original table is restored after the nested steps are executed')
        def step_table_is_restored(context):
            assert context.my_table1 is not None
            assert context.my_table2 is not None
            assert context.my_table1 is context.my_table2
        """
    And a file named "features/steps/text_steps.py" with:
        """
        from behave import when, then, step
        @step('I use another step with text "{text}"')
        def step_use_another_text_with(context, text):
            assert context.text is None
            context.text = text     # -- MODIFY: context.text (emulation)
        @step('I use another text with')
        def step_use_another_text_with(context):
            assert context.text is not None, "REQUIRE: text"
            context.nested_text = context.text
        @when('I execute the nested steps and use the text')
        def step_execute_nested_steps_and_use_text(context):
            assert context.text is not None, "REQUIRE: text"
            assert context.nested_steps, "REQUIRE: context.nested_steps"
            context.my_text1 = context.text
            context.execute_steps(context.nested_steps)
            context.my_text2 = context.text
        @then('the original text is restored after the nested steps are executed')
        def step_text_is_restored(context):
            assert context.my_text1 is not None
            assert context.my_text2 is not None
            assert context.my_text1 is context.my_text2
        """

  @nested_steps.with_table
  Scenario: After executing simple nested steps the original table is restored
    Given a file named "features/example.nested_simple_steps_and_table.feature" with:
        """
        Feature:
          Scenario:
            Given I define the following nested steps:
                '''
                Given a step passes
                When another step passes
                '''
            When I execute the nested steps and use the table:
                | Name   | Age |
                | Alice  | 21  |
                | Bob    | 32  |
            Then the original table is restored after the nested steps are executed
        """
    When I run "behave -f plain -T features/example.nested_simple_steps_and_table.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """

  @nested_steps.with_table
  Scenario: After executing nested steps with a table the original table is restored
    Given a file named "features/example.nested_steps_and_table.feature" with:
        """
        Feature:
          Scenario:
            Given I define the following nested steps:
                '''
                Given I use another table with:
                    | Person | Registered |
                    | Anton  | true  |
                    | Barby  | false |
                '''
            When I execute the nested steps and use the table:
                | Name   | Age |
                | Charly | 41  |
                | Doro   | 52  |
            Then the original table is restored after the nested steps are executed
        """
    When I run "behave -f plain -T features/example.nested_steps_and_table.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """


  @nested_steps.with_text
  Scenario: After executing simple nested steps the original text is restored
    Given a file named "features/example.nested_simple_steps_and_text.feature" with:
        """
        Feature:
          Scenario:
            Given I define the following nested steps:
                '''
                Given a step passes
                When another step passes
                '''
            When I execute the nested steps and use the text:
                '''
                Lorem ipsum
                Ipsum lorem
                '''
            Then the original text is restored after the nested steps are executed
        """
    When I run "behave -f plain -T features/example.nested_simple_steps_and_text.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """

  @nested_steps.with_text
  Scenario: After executing nested steps with a text the original text is restored
    Given a file named "features/example.nested_steps_and_text.feature" with:
        """
        Feature:
          Scenario:
            Given I define the following nested steps:
                '''
                Given I use another step with text "Hello Alice"
                '''
            When I execute the nested steps and use the text:
                '''
                Lorem ipsum
                Ipsum lorem
                '''
            Then the original text is restored after the nested steps are executed
        """
    When I run "behave -f plain -T features/example.nested_steps_and_text.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """
@issue
Feature: Issue #194: Nested steps prevent that original stdout/stderr is restored

  . When nested steps are used,
  . the original stdout/stderr streams are not restored after the scenario.
  . This is caused by starting/stopping capture again while executing nested steps.
  .
  . ENSURE THAT:
  .   * Original streams are restored in after_scenario() hook.
  .   * Nested steps should not replace existing capture objects.

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "behave.ini" with:
        """
        [behave]
        log_capture = false
        logging_level  = INFO
        logging_format = LOG.%(levelname)-8s  %(name)s: %(message)s
        """
    And a file named "features/steps/use_behave4cmd_steps.py" with:
        """
        import behave4cmd0.passing_steps
        import behave4cmd0.failing_steps
        import behave4cmd0.note_steps
        """
    And a file named "features/steps/stdout_steps.py" with:
        """
        from behave import given, when, then, step, matchers
        import parse
        import sys
        # -- USER-DEFINED DATA TYPES:
        @parse.with_pattern(r"stdout|stderr")
        def parse_stream_name(text):
            assert text in ("stdout", "stderr")
            return text
        matchers.register_type(StreamName=parse_stream_name)
        # -- UTILITY FUNCTIONS:
        def write_text_to(stream, text, enforce_newline=True):
            if enforce_newline and not text.endswith("\n"):
                text += "\n"
            stream.write(text)
        # -- STEP DEFINITIONS:
        @step('I write "{text}" to {stream_name:StreamName}')
        def step_write_text_to_stdxxx(context, text, stream_name):
            stream = getattr(sys, stream_name)
            write_text_to(stream, text)
        @step('I execute the following steps')
        def step_execute_steps(context):
            assert context.text, "REQUIRE: context.text"
            context.execute_steps(context.text)
            sys.stdout.write("STDOUT:AFTER-EXECUTE-STEPS\n")
            sys.stderr.write("STDERR:AFTER-EXECUTE-STEPS\n")
        """
    And a file named "features/environment.py" with:
        """
        import sys
        stdout_id = 0
        stderr_id = 0
        def stdout_print(text):
            sys.__stdout__.write(text + "\n")
        def inspect_stdout(context, scope, statement):
            global stdout_id
            stream_id = id(sys.stdout)
            stream_class = sys.stdout.__class__.__name__
            expected_id = stdout_id
            if stream_id != expected_id:
                name = statement.name
                stdout_print("CHANGED-STDOUT %s:%s: stream.id=%s:%d (was: %d)" % \
                            (scope, name, stream_class, stream_id, expected_id))
                stdout_id = stream_id
        def inspect_stderr(context, scope, statement):
            global stderr_id
            stream_id = id(sys.stderr)
            stream_class = sys.stderr.__class__.__name__
            expected_id = stderr_id
            if stream_id != expected_id:
                name = statement.name
                stdout_print("CHANGED-STDERR %s:%s: stream.id=%s:%d (was: %d)" % \
                            (scope, name, stream_class, stream_id, expected_id))
                stderr_id = stream_id
        def inspect_stdxxx(context, scope, statement):
            inspect_stdout(context, scope, statement)
            inspect_stderr(context, scope, statement)
        def before_all(context):
            context.config.setup_logging(filename="behave.log")
        def before_scenario(context, scenario):
            inspect_stdxxx(context, "before_scenario", scenario)
        def after_scenario(context, scenario):
            inspect_stdxxx(context, "after_scenario", scenario)
            # -- ENSURE: Original streams are restored.
            assert sys.stdout is sys.__stdout__
            assert sys.stderr is sys.__stderr__
            stdout_print("AFTER-SCENARIO %s: Streams are restored." % scenario.name)
        def before_step(context, step):
            inspect_stdxxx(context, "before_step", step)
        def after_step(context, step):
            inspect_stdxxx(context, "after_step", step)
        """

  Scenario: Stdout capture works with nested steps
    Given a file named "features/stdout.failing_with_nested.feature" with
        """
        Feature:
          Scenario: Failing with nested steps
            Given I write "STDOUT:Hello Alice" to stdout
            When  I write "STDOUT:Hello Bob" to stdout
            Then  I execute the following steps:
              '''
              * I write "STDOUT:Hello nested.Alice" to stdout
              * I write "STDOUT:Hello nested.Bob" to stdout
              '''
            And I write "STDOUT:Hello Charly" to stdout
            And another step fails
          Scenario: Another failing
            Given I write "STDOUT:Hello Dora" to stdout
            And another step fails
        """
    When I run "behave -f plain features/stdout.failing_with_nested.feature"
    Then it should fail with:
        """
        0 scenarios passed, 2 failed, 0 skipped
        5 steps passed, 2 failed, 0 skipped, 0 undefined
        """
    And note that "the summary is only shown if hooks have no errors"
    And the command output should contain:
        """
        Captured stdout:
        STDOUT:Hello Alice
        STDOUT:Hello Bob
        STDOUT:Hello nested.Alice
        STDOUT:Hello nested.Bob
        STDOUT:AFTER-EXECUTE-STEPS
        STDOUT:Hello Charly
        """
    And the command output should contain:
        """
        Captured stdout:
        STDOUT:Hello Dora
        """
    And the command output should contain:
        """
        AFTER-SCENARIO Failing with nested steps: Streams are restored.
        """
    And the command output should contain:
        """
        AFTER-SCENARIO Another failing: Streams are restored.
        """

  Scenario: Stderr capture works with nested steps
    Given a file named "features/stderr.failing_with_nested.feature" with
        """
        Feature:
          Scenario: Failing with nested steps
            Given I write "STDERR:Hello Alice" to stderr
            When  I write "STDERR:Hello Bob" to stderr
            Then  I execute the following steps:
              '''
              * I write "STDERR:Hello nested.Alice" to stderr
              * I write "STDERR:Hello nested.Bob" to stderr
              '''
            And I write "STDERR:Hello Charly" to stderr
            And another step fails
          Scenario: Another failing
            Given I write "STDERR:Hello Dora" to stderr
            And another step fails
        """
    When I run "behave -f plain features/stderr.failing_with_nested.feature"
    Then it should fail with:
        """
        0 scenarios passed, 2 failed, 0 skipped
        5 steps passed, 2 failed, 0 skipped, 0 undefined
        """
    And note that "the summary is only shown if hooks have no errors"
    And the command output should contain:
        """
        Captured stderr:
        STDERR:Hello Alice
        STDERR:Hello Bob
        STDERR:Hello nested.Alice
        STDERR:Hello nested.Bob
        STDERR:AFTER-EXECUTE-STEPS
        STDERR:Hello Charly
        """
    And the command output should contain:
        """
        Captured stderr:
        STDERR:Hello Dora
        """
    And the command output should contain:
        """
        AFTER-SCENARIO Failing with nested steps: Streams are restored.
        """
    And the command output should contain:
        """
        AFTER-SCENARIO Another failing: Streams are restored.
        """
@issue
Feature: Issue #197: Hooks processing should be more exception safe

  TESTS PROVIDED IN: features/runner.hook_errors.feature

  @reuse.colocated_test
  Scenario: Hook processing in case of errors
    Given I use the current directory as working directory
    When I run "behave -f plain features/runner.hook_errors.feature"
    Then it should pass
@issue
Feature: Issue #216: ANSI escape sequences are used while using --wip option

  . ENSURE THAT:
  .   * Coloring is disabled when --wip option is used.
  .   * In addition, no colouring is used when using --show-skipped option
  .   * Undefined step snippets are not "colored".

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "behave.ini" with:
        """
        [behave]
        default_format = pretty
        show_skipped   = false
        show_timings   = false
        """
    And a file named "features/steps/use_behave4cmd_steps.py" with:
        """
        import behave4cmd0.passing_steps
        import behave4cmd0.failing_steps
        import behave4cmd0.note_steps
        """
    And a file named "features/steps/ansi_steps.py" with:
        """
        from behave import step, then
        from behave4cmd0.command_steps import step_command_output_should_not_contain_text
        @then(u'the command output should not contain any ANSI escape sequences')
        def step_command_ouput_should_not_contain_ansi_sequences(context):
            CSI = u"\x1b["  #< ANSI CONTROL SEQUENCE INTRODUCER (CSI).
            step_command_output_should_not_contain_text(context, CSI)
        """
    And a file named "features/scenario_with_undefined_steps.feature" with:
        """
        Feature:
          @wip
          Scenario: Alice
            Given a step passes
            When a step is undefined
            Then a step passes
          @foo
          Scenario: Bob
            When another step is undefined
        """


  Scenario: When using --wip, coloring is disabled
    When I run "behave --wip features"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      0 scenarios passed, 1 failed, 0 skipped, 1 untested
      1 step passed, 0 failed, 1 skipped, 1 undefined, 1 untested
      """
    And the command output should contain:
      """
      Scenario: Alice
        Given a step passes ... passed
        When a step is undefined ... undefined
      """
    But the command output should not contain any ANSI escape sequences
    And note that "the plain formatter is used as default formatter"


  Scenario: When using --wip and --show-skipped, coloring is disabled
    When I run "behave --wip --show-skipped features"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      0 scenarios passed, 1 failed, 0 skipped, 1 untested
      1 step passed, 0 failed, 1 skipped, 1 undefined, 1 untested
      """
    And the command output should contain:
      """
      Scenario: Alice
        Given a step passes ... passed
        When a step is undefined ... undefined
      """
    But the command output should not contain any ANSI escape sequences
    And note that "the plain formatter is used as default formatter"


  Scenario: When using --wip and --format, coloring is disabled
    When I run "behave --wip -f pretty features"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      0 scenarios passed, 1 failed, 0 skipped, 1 untested
      1 step passed, 0 failed, 1 skipped, 1 undefined, 1 untested
      """
    And the command output should contain:
      """
      Feature:  # features/scenario_with_undefined_steps.feature:1
        @wip
        Scenario: Alice            # features/scenario_with_undefined_steps.feature:4
          Given a step passes      # ../behave4cmd0/passing_steps.py:23
          When a step is undefined # None
          Then a step passes       # None
      """
    But the command output should not contain any ANSI escape sequences
    And note that "the plain formatter is overridden on command-line"
    And note that "the coloring mode is disabled"


  Scenario: When using --wip and --color, coloring is disabled
    When I run "behave --wip -f pretty --color features"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      0 scenarios passed, 1 failed, 0 skipped, 1 untested
      1 step passed, 0 failed, 1 skipped, 1 undefined, 1 untested
      """
    And the command output should contain:
      """
      Feature:  # features/scenario_with_undefined_steps.feature:1
        @wip
        Scenario: Alice            # features/scenario_with_undefined_steps.feature:4
          Given a step passes      # ../behave4cmd0/passing_steps.py:23
          When a step is undefined # None
          Then a step passes       # None
      """
    But the command output should not contain any ANSI escape sequences
    And note that "the coloring mode is overridden by the wip mode"
@issue
@unicode
Feature: UnicodeDecodeError in tracebacks (when an exception in a step implementation)

  . Exception with non-ASCII character is raised in a step implementation.
  . UnicodeDecodeError occurs with:
  .   'ascii' codec can't decode byte 0x82 in position 11: ordinal not in range(128)
  .
  . RELATED:
  .   * features/i18n.unicode_problems.feature

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
      """
      # -*- coding: UTF-8 -*-
      from behave import step
      import six
      if six.PY2:
          chr = unichr
      @step(u'a step raises an exception with non-ASCII character "{char_code:d}"')
      def step_raises_exception_with_non_ascii_text(context, char_code):
          assert 0 <= char_code <= 255, "RANGE-ERROR: char_code=%s" % char_code
          raise RuntimeError(u"FAIL:"+ chr(char_code) +";")
      """

  Scenario Outline: Syndrome with non-ASCII char <char_code> (format=<format>)
    Given a file named "features/syndrome_0226_<char_code>.feature" with:
      """
      Feature:
        Scenario:
          Given a step raises an exception with non-ASCII character "<char_code>"
      """
    When I run "behave -f <format> features/syndrome_0226_<char_code>.feature"
    Then it should fail with:
      """
      0 scenarios passed, 1 failed, 0 skipped
      0 steps passed, 1 failed, 0 skipped, 0 undefined
      """
    And the command output should contain:
      """
      RuntimeError: FAIL:<special_char>;
      """
    But the command output should not contain "UnicodeDecodeError"

    Examples:
      | format | char_code | special_char | comment! |
      | plain  |    162    |             | cent     |
      | pretty |    191    |             | question-mark on-the-head |
@feature_request
@issue
Feature: Issue #228: Allow before_scenario to determine whether steps should be run.

  Allow before_scenario to call mark_skipped() and early out if the current
  scenario should be skipped.

  Scenario: Allow before_scenario to skip the current scenario

    Given a new working directory
    And a file named "features/steps/steps.py" with:
        """
        from behave import step
        @step('a step passes')
        def step_passes(context):
            pass
        """
    And a file named "features/environment.py" with
        """
        def before_scenario(context, scenario):
            if scenario.name == 'Skip this scenario':
                scenario.skip()
        """
    And a file named "features/issue228_example.feature" with
        """
        Feature:
          Scenario: Skip this scenario
            Given I'm using an "undefined step"
          Scenario: Run this scenario
            Given a step passes
        """
    When I run "behave -f plain features/issue228_example.feature"
    Then it should pass
     And the command output should contain:
        """
        1 feature passed, 0 failed, 0 skipped
        1 scenario passed, 0 failed, 1 skipped
        1 step passed, 0 failed, 1 skipped, 0 undefined
        """
@issue
@unicode
Feature: Assert with non-ASCII char causes UnicodeDecodeError

  . Failing assert with non-ASCII character in its message
  . causes UnicodeDecodeError and silent exit in Python2.
  .
  . RELATED:
  .   * features/i18n.unicode_problems.feature

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
      """
      from behave import step
      @step(u'a step fails with non-ASCII character "{char_code:d}"')
      def step_fails_with_non_ascii_text(context, char_code):
          assert 0 <= char_code <= 255, "RANGE-ERROR: char_code=%s" % char_code
          assert False, "FAIL:"+ chr(char_code) +";"
      """

  Scenario Outline: Syndrome with non-ASCII char <char_code> (format=<format>)
    Given a file named "features/syndrome_0230_<char_code>.feature" with:
      """
      Feature:
        Scenario:
          Given a step fails with non-ASCII character "<char_code>"
      """
    When I run "behave -f <format> features/syndrome_0230_<char_code>.feature"
    Then it should fail with:
      """
      0 scenarios passed, 1 failed, 0 skipped
      0 steps passed, 1 failed, 0 skipped, 0 undefined
      """
    And the command output should not contain "UnicodeDecodeError"
    But the command output should contain:
      """
      Assertion Failed: FAIL:
      """

    Examples:
      | format | char_code |
      | plain  |    130    |
      | pretty |    190    |


@issue
@not_reproducible
Feature: Issue #231: Display the output of the last print command

  . The output of the last print command in a step is not displayed
  . in the behave output (at least with standard pretty formatter),
  . unless the string to print ends with newline ('\n').
  .
  . ANALYSIS: NOT-REPRODUCIBLE
  .   Checked print function and stdout without newline.
  .   Both show the expected capture stdout output when the step fails.

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/syndrome1.feature" with:
      """
      Feature:
        Scenario: Alice
           Given a step passes
           When  a step passes
           Then  I write "ALICE was HERE" without newline to stdout and fail
      """
    And a file named "features/syndrome2.feature" with:
      """
      Feature:
        Scenario: Bob
           Given a step passes
           Then  I print "BOB was HERE" without newline and fail
      """
    And a file named "features/steps/steps.py" with:
      """
      from __future__ import print_function
      from behave import step
      import sys
      @step('{word:w} step passes')
      def step_passes(context, word):
          pass
      @step('I write "{message}" without newline to stdout and fail')
      def step_write_without_newline_and_fail(context, message):
          sys.stdout.write(message)
          assert False, "FAIL: "+ message
      @step('I print "{message}" without newline and fail')
      def step_print_without_newline_and_fail(context, message):
          print(message, end="")
          assert False, "FAIL: "+ message
      """


  Scenario: Write to stdout without newline
    When I run "behave -f pretty -c -T features/syndrome1.feature"
    Then it should fail with:
      """
      0 scenarios passed, 1 failed, 0 skipped
      2 steps passed, 1 failed, 0 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Captured stdout:
      ALICE was HERE
      """

  Scenario: Use print function without newline
    When I run "behave -f pretty -c -T features/syndrome2.feature"
    Then it should fail with:
      """
      0 scenarios passed, 1 failed, 0 skipped
      1 step passed, 1 failed, 0 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Captured stdout:
      BOB was HERE
      """
@issue
@feature_request
Feature: Issue #238 Skip a Scenario in a Scenario Outline

    Scenario:
      Given a new working directory
      And a file named "features/issue238_1.feature" with:
        """
        Feature: Testing Scenario skipping
            Scenario Outline:
                Given a set of "<thing>"
                When I ensure that "<thing>" != invalid
                Then it should pass
              Examples:
                | thing   |
                | valid   |
                | invalid |
        """
      And a file named "features/steps/steps.py" with:
        """
        @given('a set of "{thing}"')
        def step_check_thing_assumption(ctx, thing):
            if thing == "invalid":
                ctx.scenario.skip("ASSUMPTION-MISMATCH: INVALID-THING")
        @when('I ensure that "{thing}" != invalid')
        def step_ensure_that_thing_is_valid(ctx, thing):
            assert thing != "invalid"
        @then('it should pass')
        def step_passes(context):
            pass
        """
      When I run "behave -f plain --show-skipped --no-timings"
      Then it should pass with:
        """
        1 feature passed, 0 failed, 0 skipped
        1 scenario passed, 0 failed, 1 skipped
        3 steps passed, 0 failed, 3 skipped, 0 undefined
        """
      And the command output should contain:
        """
        Scenario Outline:  -- @1.1
          Given a set of "valid" ... passed
          When I ensure that "valid" != invalid ... passed
          Then it should pass ... passed
        Scenario Outline:  -- @1.2
          Given a set of "invalid" ... skipped
        """
      But note that "the step that skipped the scenario is also marked as skipped"
@issue
@unicode
Feature: UnicodeDecodeError in model.Step (when step fails)

  . Output of failing step contains non-ASCII characters.
  .
  . RELATED:
  .   * features/i18n.unicode_problems.feature


  @reuse.colocated_test
  Scenario:
      Given I use the current directory as working directory
      When I run "behave -f plain --tags=@setup,@problematic.output features/i18n.unicode_problems.feature"
      Then it should pass
@issue
Feature: Issue #280: AmbiguousStep error with similar step definitions and use_step_matcher("re")
  . While using the RegexMatcher with steps that have the same step prefix
  . an AmbiguousStep exception occurs if the shorter step is registered first.
  .
  . EXAMPLE:
  . Two steps with definitions that have the same step prefix:
  .
  .   * I do something
  .   * I do something more
  .
  . cause an AmbiguousStep error to be thrown:
  .
  .   behave.step_registry.AmbiguousStep: @when('I do something more') has already
  .   been defined in existing step @when('I do something') at ...
  .
  . SOLUTION: Add regex begin-/end-markers around the step text( '^'+ step + '$')
  . NOTE: Only RegexMatcher is affected.
  @setup
  Scenario: Feature Setup
    Given a new working directory
    And   a file named "features/steps/calculator_steps1.py" with:
      """
      from behave import given, then
      from hamcrest import assert_that, equal_to

      class SimpleCalculator(object):
          def __init__(self):
              self.result = 0

          def add(self, value):
              self.result += value

      @given(u'a calculator')
      def step_impl(context):
          context.calculator = SimpleCalculator()

      @then(u'the calculator result is "{expected_result:d}"')
      def step_impl(context, expected_result):
          assert_that(context.calculator.result, equal_to(expected_result))
      """
  Scenario: Ensure RegexMatcher is not ordering sensitive
    Given a file named "features/syndrome_280_1.feature" with:
      """
      Feature:
        Scenario: Use both steps
          Given I do something
          When  I do something more
      """
    And   a file named "features/steps/simple_steps.py" with:
      """
      from behave import step, use_step_matcher
      use_step_matcher("re")

      # -- ORDERING SENSITIVE PART:
      @step(u'I do something')
      def step_impl(context):
          pass

      @step(u'I do something more')
      def step_impl(context):
          pass
      """
    When I run "behave -f plain features/syndrome_280_1.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      """
    But the command output should not contain "AmbiguousStep:"
    And the command output should not contain:
      """
      AmbiguousStep: @step('I do something more') has already been defined in
      existing step @step('I do something') at features/steps/simple_steps.py:5'
      """
  Scenario: Ensure correct step implementation is selected
    Given a file named "features/syndrome_280_2.feature" with:
      """
      Feature: Steps with same step prefix -- Use correct step implementation
        Scenario: Use shorter step
          Given a calculator
          When I add "2" to it
          And  I add "3" to it
          Then the calculator result is "5"
        Scenario: Use longer step
          Given a calculator
          When I add "2" to it twice
          And  I add "3" to it
          Then the calculator result is "7"
      """
    And   a file named "features/steps/calculator_steps2.py" with:
      """
      from behave import when, use_step_matcher
      use_step_matcher("re")
      # -- ORDERING SENSITIVE PART:
      @when(u'I add "(?P<value>\d+)" to it')
      def step_impl(context, value):
          number_value = int(value)
          context.calculator.add(number_value)

      @when(u'I add "(?P<value>\d+)" to it twice')
      def step_impl(context, value):
          number_value = int(value)
          context.calculator.add(number_value)
          context.calculator.add(number_value)
      """
    When I run "behave -f pretty --no-color features/syndrome_280_2.feature"
    Then it should pass with:
      """
      When I add "2" to it twice        # features/steps/calculator_steps2.py:10
      And I add "3" to it               # features/steps/calculator_steps2.py:5
      """
    But the command output should not contain "AmbiguousStep"
@issue
Feature: Issue #288 -- Use print function instead print statement in environment/steps files

  . Loaded files have future flags of importing module "behave.runner".
  . This should be removed.
  .
  . AFFECTED FILES:
  .   * features/environment.py
  .   * features/steps/*.py
  .
  . AFFECTED FUTURE FLAGS:
  .   * print_function
  .   * absolute_import
  .   * ...

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/reuse_steps.py" with:
        """
        from behave4cmd0 import passing_steps
        """
    And a file named "features/passing.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
        """

  @preferred
  Scenario: Use print function with future-statement in steps/environment (PY2, PY3)
    Given a file named "features/steps/my_steps.py" with:
        """
        from __future__ import print_function
        print("Hello step")
        """
    And a file named "features/environment.py" with:
        """
        from __future__ import print_function
        print("Hello environment")
        """
    When I run "behave -f plain features/passing.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        1 step passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should not contain:
        """
        Traceback (most recent call last):
        """

  @use.with_python2=true
  Scenario: Use python2 print keyword in steps/environment
    Given a file named "features/steps/my_steps.py" with:
        """
        print "Hello step"
        """
    And a file named "features/environment.py" with:
        """
        print "Hello step"
        """
    When I run "behave -f plain features/passing.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        1 step passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should not contain "SyntaxError"
    And the command output should not contain:
        """
        Traceback (most recent call last):
        """

  @use.with_python3=true
  Scenario: Use print function without future-statement in steps/environment (PY3)
    Given a file named "features/steps/my_steps.py" with:
        """
        print("Hello step")
        """
    And a file named "features/environment.py" with:
        """
        print("Hello environment")
        """
    When I run "behave -f plain features/passing.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        1 step passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should not contain:
        """
        Traceback (most recent call last):
        """
@issue
Feature: Issue #300 -- UnicodeDecodeError when read steps.py

  . My system is running on Chinese GBK character set.
  . But you know we make our files as utf-8 format generally, and so do I.
  . I set my step file api1_steps.py as utf-8, and entered some Chinese characters in.
  . I run "behave", but I got UnicodeDecodeError, just like this:
  .
  .   File "D:\workspace\env_110\lib\site-packages\behave\runner.py", line 304, in exec_file
  .     code = compile(f.read(), filename2, 'exec')
  .   UnicodeDecodeError: 'gbk' codec can't decode byte 0xad in position 510: illegal multibyte sequence

  | OPEN ISSUES:
  |   * Acceptable/supported Python source file encodings
  |   * config: Add encoding option for feature files, step files or both.
    Scenario: Cause BAD-ASCII Syndrome in steps file
        Given a new working directory
        And a file named "features/steps/bad_ascii_steps.py" with:
            """
            '''
            BAD ASCII CASES (requires UTF-8/latin1 support):
             * Caf
             * rgernis ist berall
            '''
            # COMMENT: rgernis ist berall
            """
        And a file named "features/steps/steps.py" with:
            """
            from __future__ import unicode_literals
            from behave import step
            @step('{word:w} step passes')
            def step_passes(context, word):
                pass
            """
        And a file named "features/e1.feature" with:
            """
            Feature:
              Scenario: Alice
                Given a step passes
                Then another step passes
            """
        When I run "behave -f plain features/e1.feature"
        Then it should pass with:
            """
            1 scenario passed, 0 failed, 0 skipped
            2 steps passed, 0 failed, 0 skipped, 0 undefined
            """
@issue
Feature: Issue #302: Cannot escape pipe in table field value

  Support escaped-pipe characters in cells of a table.

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
        """
        from behave import then, step
        from hamcrest import assert_that, equal_to
        @step(u'I use table data with')
        def step_use_table_data_with_table(context):
            assert context.table, "REQUIRE: context.table is provided"
            context.table.require_columns(["name", "value"])
            context.table_data = {}
            for row in context.table.rows:
                name = row["name"]
                value = row["value"]
                context.table_data[name] = value
        @then(u'table data "{name}" is "{value}"')
        def step_table_data_name_is_value(context, name, value):
            table_data = context.table_data
            actual_value = table_data[name]
            assert_that(actual_value, equal_to(value))
        """

  Scenario: Escaped-pipes in table cell
    Given a file named "features/issue0302_example.feature" with:
        """
        Feature:
            Scenario: Use a table
             Given I use table data with:
                 | name  | value |
                 | alice | one\|two\|three\|four  |
             Then table data "alice" is "one|two|three|four"
        """
    When I run "behave -f plain features/issue0302_example.feature"
    Then it should pass
    And the command output should not contain:
        """
        Traceback (most recent call last):
        """


  Scenario: Leading escaped-pipe in table cell
    Given a file named "features/issue0302_example2.feature" with:
        """
        Feature:
            Scenario: Use a table
             Given I use table data with:
                 | name  | value |
                 | bob   |\|one  |
             Then table data "bob" is "|one"
        """
    When I run "behave -f plain features/issue0302_example2.feature"
    Then it should pass


  Scenario: Trailing escaped-pipe in table cell
    Given a file named "features/issue0302_example3.feature" with:
        """
        Feature:
            Scenario: Use a table
             Given I use table data with:
                 | name   | value |
                 | charly | one\||
             Then table data "charly" is "one|"
        """
    When I run "behave -f plain features/issue0302_example3.feature"
    Then it should pass


  Scenario: Double escaped-pipe in table cell
    Given a file named "features/issue0302_example4.feature" with:
        """
        Feature:
            Scenario: Use a table
             Given I use table data with:
                 | name   | value |
                 | doro   | one\\|two |
             Then table data "doro" is "one\|two"
        """
    When I run "behave -f plain features/issue0302_example4.feature"
    Then it should pass

@issue
Feature: Issue #309 -- behave --lang-list fails on Python3

  . When I type "behave --lang-list", the following error occurs on Python 3.4:
  .
  .   Traceback (most recent call last):
  .     File "/usr/local/bin/behave", line 11, in <module>
  .       sys.exit(main())
  .     File "/usr/local/lib/python3.4/dist-packages/behave/__main__.py", line 65, in main
  .       iso_codes.sort()
  .   AttributeError: 'dict_keys' object has no attribute 'sort'
  .
  . ADDITIONAL PROBLEM: On Python2 you may get an UnicodeDecodeError
  .   Traceback (most recent call last):
  .     ...
  .   Languages available:
  .     File "/Users/jens/se/behave_main.fix/behave/__main__.py", line 70, in main
  .       print(u'%s: %s / %s' % (iso_code, native, name))
  .   UnicodeEncodeError: 'ascii' codec can't encode characters in position 4-10: ordinal not in range(128)
  .
  . RELATED FEATURES:
  .  * features/cmdline.lang_list.feature
  .


  @problematic
  @not.with_os=win32
  Scenario: Use behave --lang-list
    When I run "behave --lang-list"
    Then it should pass with:
        """
        Languages available:
          af: Afrikaans / Afrikaans
          am:  / Armenian
          an: Aragons / Aragonese
          ar:  / Arabic
          ast: asturianu / Asturian
          az: Azrbaycanca / Azerbaijani
          bg:  / Bulgarian
          bm: Bahasa Melayu / Malay
          bs: Bosanski / Bosnian
          ca: catal / Catalan
          cs: esky / Czech
          cy-GB: Cymraeg / Welsh
          da: dansk / Danish
          de: Deutsch / German
          el:  / Greek
          em:  / Emoji
          en: English / English
        """
    And the command output should contain:
        """
        sv: Svenska / Swedish
        ta:  / Tamil
        th:  / Thai
        tl:  / Telugu
        tlh: tlhIngan / Klingon
        tr: Trke / Turkish
        tt:  / Tatar
        uk:  / Ukrainian
        ur:  / Urdu
        uz:  / Uzbek
        vi: Ting Vit / Vietnamese
        zh-CN:  / Chinese simplified
        zh-TW:  / Chinese traditional
        """
    But the command output should not contain "Traceback"
@issue
Feature: Issue #330: Skipped scenarios are included in junit reports when --no-skipped is used

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/steps.py" with:
      """
      from behave import step
      @step('{word:w} step passes')
      def step_passes(context, word):
          pass
      """
    And a file named "features/alice.feature" with:
      """
      @tag1
      Feature: Alice
        Scenario: Alice1
          Given a step passes
      """
    And a file named "features/bob.feature" with:
      """
      Feature: Bob
        Scenario: Bob1
          Given another step passes
      """
    And a file named "features/charly.feature" with:
      """
      Feature: Charly
        @tag1
        Scenario: Charly1
          Given some step passes
        Scenario: Charly2
          When another step passes
      """
    And a file named "alice_and_bob.featureset" with:
      """
      features/alice.feature
      features/bob.feature
      """
    And a file named "behave.ini" with:
      """
      [behave]
      default_format  = plain
      junit_directory = test_results
      [behave.userdata]
      behave.reporter.junit.show_timestamp = false
      behave.reporter.junit.show_hostname = false
      """

  Scenario: Junit report for skipped feature is not created with --no-skipped
    When I run "behave --junit -t @tag1 --no-skipped @alice_and_bob.featureset"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 1 skipped
      """
    And a file named "test_results/TESTS-alice.xml" exists
    And a file named "test_results/TESTS-bob.xml" does not exist
    And the command output should contain:
      """
      Feature: Alice
        Scenario: Alice1
          Given a step passes ... passed
      """
    But the command output should not contain "Feature: Bob"
    And note that "bob.feature is skipped"


  @not.with_python.version=3.8
  Scenario: Junit report for skipped feature is created with --show-skipped
    When I run "behave --junit -t @tag1 --show-skipped @alice_and_bob.featureset"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 1 skipped
      """
    And a file named "test_results/TESTS-alice.xml" exists
    And a file named "test_results/TESTS-bob.xml" exists
    And the file "test_results/TESTS-bob.xml" should contain:
      """
      <testsuite errors="0" failures="0" name="bob.Bob" skipped="1" tests="1" time="0.0">
      """

  @use.with_python.version=3.8
  Scenario: Junit report for skipped feature is created with --show-skipped
    When I run "behave --junit -t @tag1 --show-skipped @alice_and_bob.featureset"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 1 skipped
      """
    And a file named "test_results/TESTS-alice.xml" exists
    And a file named "test_results/TESTS-bob.xml" exists
    And the file "test_results/TESTS-bob.xml" should contain:
      """
      <testsuite name="bob.Bob" tests="1" errors="0" failures="0" skipped="1" time="0.0">
      """
      # -- HINT FOR: Python < 3.8
      # <testsuite errors="0" failures="0" name="bob.Bob" skipped="1" tests="1" time="0.0">

  @not.with_python.version=3.8
  Scenario: Junit report for skipped scenario is neither shown nor counted with --no-skipped
    When I run "behave --junit -t @tag1 --no-skipped"
    Then it should pass with:
      """
      2 features passed, 0 failed, 1 skipped
      2 scenarios passed, 0 failed, 2 skipped
      """
    And a file named "test_results/TESTS-alice.xml" exists
    And a file named "test_results/TESTS-charly.xml" exists
    And the file "test_results/TESTS-charly.xml" should contain:
      """
      <testsuite errors="0" failures="0" name="charly.Charly" skipped="0" tests="1"
      """
    And the file "test_results/TESTS-charly.xml" should not contain:
      """
      <testcase classname="charly.Charly" name="Charly2"
      """
    And note that "Charly2 is the skipped scenarion in charly.feature"

  @use.with_python.version=3.8
  Scenario: Junit report for skipped scenario is neither shown nor counted with --no-skipped
    When I run "behave --junit -t @tag1 --no-skipped"
    Then it should pass with:
      """
      2 features passed, 0 failed, 1 skipped
      2 scenarios passed, 0 failed, 2 skipped
      """
    And a file named "test_results/TESTS-alice.xml" exists
    And a file named "test_results/TESTS-charly.xml" exists
    And the file "test_results/TESTS-charly.xml" should contain:
      """
      <testsuite name="charly.Charly" tests="1" errors="0" failures="0" skipped="0"
      """
      # -- HINT FOR: Python < 3.8
      # <testsuite errors="0" failures="0" name="charly.Charly" skipped="0" tests="1"
    And the file "test_results/TESTS-charly.xml" should not contain:
      """
      <testcase classname="charly.Charly" name="Charly2"
      """
    And note that "Charly2 is the skipped scenarion in charly.feature"


  @not.with_python.version=3.8
  Scenario: Junit report for skipped scenario is shown and counted with --show-skipped
    When I run "behave --junit -t @tag1 --show-skipped"
    Then it should pass with:
      """
      2 features passed, 0 failed, 1 skipped
      2 scenarios passed, 0 failed, 2 skipped
      """
    And a file named "test_results/TESTS-alice.xml" exists
    And a file named "test_results/TESTS-charly.xml" exists
    And the file "test_results/TESTS-charly.xml" should contain:
      """
      <testsuite errors="0" failures="0" name="charly.Charly" skipped="1" tests="2"
      """
    And the file "test_results/TESTS-charly.xml" should contain:
      """
      <testcase classname="charly.Charly" name="Charly2" status="skipped"
      """
    And note that "Charly2 is the skipped scenarion in charly.feature"


  @use.with_python.version=3.8
  Scenario: Junit report for skipped scenario is shown and counted with --show-skipped
    When I run "behave --junit -t @tag1 --show-skipped"
    Then it should pass with:
      """
      2 features passed, 0 failed, 1 skipped
      2 scenarios passed, 0 failed, 2 skipped
      """
    And a file named "test_results/TESTS-alice.xml" exists
    And a file named "test_results/TESTS-charly.xml" exists
    And the file "test_results/TESTS-charly.xml" should contain:
      """
      <testsuite name="charly.Charly" tests="2" errors="0" failures="0" skipped="1"
      """
      # HINT: Python < 3.8
      # <testsuite errors="0" failures="0" name="charly.Charly" skipped="1" tests="2"
    And the file "test_results/TESTS-charly.xml" should contain:
      """
      <testcase classname="charly.Charly" name="Charly2" status="skipped"
      """
    And note that "Charly2 is the skipped scenarion in charly.feature"
@issue
Feature: Issue #361 -- UTF-8 File with BOM

  . Using step files with "Byte-Order Mark" (BOM) prefix
  . causes weird problems.
  .
  . FIXES ALSO: #300
  . AFFECTED FILES:
  .   * features/environment.py
  .   * features/steps/*.py

  @setup
  Scenario: Feature Setup
    Given a new working directory
    And a file named "features/steps/reuse_steps.py" with:
        """
        from behave4cmd0 import passing_steps
        """
    And a file named "features/passing.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
            Then a special step
        """
    And a file named "behave.ini" with:
        """
        [behave]
        show_timings = false
        """


  @encoding.<encoding>
  @not.with_python.implementation=<exclude_pyimpl>
  Scenario Outline: Use step file with <case>
    Given a file named "features/steps/my_steps.py" and encoding="<encoding>" with:
        """
        # -*- coding: <encoding> -*-
        '''
        <text>.
        '''
        from behave import step
        @step(u'a special step')
        def step_impl(context):
            pass
        """
    When I run "behave -f plain features/passing.feature"
    Then it should pass with:
        """
        1 scenario passed, 0 failed, 0 skipped
        2 steps passed, 0 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Feature:
          Scenario:
            Given a step passes ... passed
            Then a special step ... passed
        """
    And the command output should not contain:
        """
        SyntaxError: invalid character in identifier
        """

    Examples:
      | encoding   | text                 | case                    | exclude_pyimpl | Comment |
      | UTF-8-sig  | rgernis ist berall | UTF-8 encoding and BOM  | pypy  | pypy SyntaxError: UTF-8 with BOM |
      | latin1     | Caf                 | Latin1 encoding         | none  |                  |
      | iso-8859-1 | rgernis ist berall | iso-8859-1 encoding     | none  | Alias for latin1 |
      | cp1252     | rgernis ist berall | cp1252 encoding         | none  | Windows: Western Europe |
      | cp1251     | ! (=hello)     | cp1251 encoding (Russia)| none  | Windows: Russia  |
      | cp866      | ! (=hello)     | cp688 encoding (Russia) | none  | IBM866:  Russia  |
      | euc_jp     |  (=hello)  | euc_jp encoding (Japan) | none  | Japanese         |
      | gbk        |  (=hello)        | gbk encoding (China)    | none  | Unified Chinese  |
      | gb2312     |  (=hello)        | gb2312 encoding (China) | none  | Simplified Chinese |

    # -- DISABLE EXAMPLE ROW: Pypy 4.x has SyntaxError with UTF-8 BOM
    # | UTF-8-sig  | rgernis ist berall | UTF-8 encoding and BOM  |  |
@issue
Feature: Issue #383 -- Handle (custom) Type parsing errors better

  . Custom type parsing errors that occur during step matching
  . lead currently to abortion of the test run.
  . In addition, the actual reason what occured is very low-level.
  .
  . DESIRED:
  .   * Protect test runner/execution logic
  .   * Improve handling of these kind of errors
  .   * Provide better diagnostics
  .   * Continue to run tests (if possible)
  .
  . NOTE:
  . This kind of problem is often caused by regular expressions that
  . are not specific enough for the type conversion (LAZY-REGEXP DESIGN).
  . Therefore, the problem occurs during type conversion/parsing phase
  . and not in the initial step detection/matching phase.
  .
  . RELATED: features/step_param.custom_types.feature


  Scenario: Type conversion fails
    Given a new working directory
    And a file named "features/steps/bad_type_converter_steps.py" with:
        """
        from behave import step, register_type
        import parse
        @parse.with_pattern(r".*")  # -- NOTE: Wildcard pattern, accepts anything.
        def parse_fails(text):
            raise ValueError(text)
        register_type(BadType=parse_fails)
        @step('a param with "BadType:{value:BadType}"')
        def step_param_with_badtype_value(context, value):
            assert False, "SHOULD_NEVER_COME_HERE: BadType converter raises error."
        """
    And a file named "features/steps/reused_steps.py" with:
        """
        from behave4cmd0 import passing_steps
        """
    And a file named "behave.ini" with:
        """
        [behave]
        show_timings = false
        """
    And a file named "features/example.type_conversion_fails.feature" with:
        """
        Feature: Type Conversion Fails
          Scenario: BadType raises ValueError during type conversion
            Given a param with "BadType:BAD_VALUE"
          Scenario: Ensure other scenarios are executed
            Then another step passes
        """
    When I run "behave -f plain features/example.type_conversion_fails.feature"
    Then it should fail with:
        """
        1 scenario passed, 1 failed, 0 skipped
        1 step passed, 1 failed, 0 skipped, 0 undefined
        """
    And the command output should contain:
        """
        Scenario: BadType raises ValueError during type conversion
          Given a param with "BadType:BAD_VALUE" ... failed
        Traceback (most recent call last):
        """
    And the command output should contain:
        """
        File "features/steps/bad_type_converter_steps.py", line 6, in parse_fails
          raise ValueError(text)
        """
    And the command output should contain "ValueError: BAD_VALUE"
    And the command output should contain "StepParseError: BAD_VALUE"
@issue
Feature: Issue #384 -- Active Tags fail with ScenarioOutline

  . ScenarioOutline can currently not be used with active-tag(s).
  . REASON: Template mechanism transforms active-tag into invalid active-tag per example row.
  .
  . RELATED: features/tag.active_tags.feature


    Background:
      Given a new working directory
      And a file named "features/steps/pass_steps.py" with:
        """
        from behave import step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        # -- REUSE: Step definitions.
        from behave4cmd0 import note_steps
        """
      And a file named "features/environment.py" with:
        """
        from behave.tag_matcher import ActiveTagMatcher, setup_active_tag_values
        import sys
        # -- ACTIVE TAG SUPPORT: @use.with_{category}={value}, ...
        active_tag_value_provider = {
            "browser":   "chrome",
            "webserver": "apache",
        }
        active_tag_matcher = ActiveTagMatcher(active_tag_value_provider)
        def before_all(context):
            setup_active_tag_values(active_tag_value_provider, context.config.userdata)
        def before_scenario(context, scenario):
            if active_tag_matcher.should_exclude_with(scenario.effective_tags):
                sys.stdout.write("ACTIVE-TAG DISABLED: Scenario %s\n" % scenario.name)
                scenario.skip(active_tag_matcher.exclude_reason)
        """
      And a file named "behave.ini" with:
        """
        [behave]
        default_format = pretty
        show_timings = no
        show_skipped = no
        color = no
        """
      And a file named "features/outline.active_tags.feature" with:
        """
        Feature:
          @use.with_browser=chrome
          Scenario Outline: Alice -- <name>, <language>
            Given a step passes
            But note that "<name> can speak <language>"
            Examples:
              | name     | language |
              | Anna     | German   |
              | Arabella | English  |
        """


    Scenario: ScenarioOutline with enabled active-tag is executed
      When I run "behave -D browser=chrome features/outline.active_tags.feature"
      Then it should pass with:
        """
        2 scenarios passed, 0 failed, 0 skipped
        4 steps passed, 0 failed, 0 skipped, 0 undefined
        """
      And the command output should contain:
        """
        @use.with_browser=chrome
        Scenario Outline: Alice -- Anna, German -- @1.1   # features/outline.active_tags.feature:10
          Given a step passes                             # features/steps/pass_steps.py:3
          But note that "Anna can speak German"           # ../behave4cmd0/note_steps.py:15
        @use.with_browser=chrome
        Scenario Outline: Alice -- Arabella, English -- @1.2   # features/outline.active_tags.feature:11
          Given a step passes                                  # features/steps/pass_steps.py:3
          But note that "Arabella can speak English"           # ../behave4cmd0/note_steps.py:15
        """
      And the command output should not contain "ACTIVE-TAG DISABLED: Scenario Alice"
      But note that "we check now for the specific syndrome"
      And the command output should not contain "@use.with_browserchrome"
      But the command output should contain "@use.with_browser=chrome"


    Scenario: ScenarioOutline with disabled active-tag is skipped
      When I run "behave -D browser=other features/outline.active_tags.feature"
      Then it should pass with:
        """
        0 scenarios passed, 0 failed, 2 skipped
        0 steps passed, 0 failed, 4 skipped, 0 undefined
        """
      And the command output should contain:
        """
        ACTIVE-TAG DISABLED: Scenario Alice -- Anna, German -- @1.1
        ACTIVE-TAG DISABLED: Scenario Alice -- Arabella, English -- @1.2
@issue
@change_request
Feature: Issue #385 -- before_scenario called too late

    . RATIONALE:
    . Due to:
    .
    .   * skip scenario/feature support in before_scenario (and before_feature) hooks
    .   * active-tags
    .
    . formatters are now called to early (for before feature/scenario functionality).
    . Formatters should be called after the before-hooks are processed.
    .
    . NOTES:
    .  * Test uses show_skipped=false to ensure that at least the
    .    scenario/feature title is shown with plain formatter.

    @setup
    Scenario:
      Given a new working directory
      And a file named "features/steps/pass_steps.py" with:
        """
        from behave import step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        """
      And a file named "features/environment.py" with:
        """
        from __future__ import print_function
        def before_feature(context, feature):
            if "skip" in feature.tags:
                print("SKIP-FEATURE: %s" % feature.name)
                feature.mark_skipped()
        def before_scenario(context, scenario):
            if "skip" in scenario.tags:
                print("SKIP-SCENARIO: %s" % scenario.name)
                scenario.mark_skipped()
        """
      And a file named "behave.ini" with:
        """
        [behave]
        show_skipped = false
        """

    Scenario: Formatter is not called with skip in before_scenario hook
      Given a file named "features/alice.feature" with:
        """
        Feature: Alice
          @skip
          Scenario: Alice and Bob
            Given a step passes
          Scenario: Alice in China
            When another step passes
        """
      When I run "behave -f plain features/alice.feature"
      Then it should pass with:
        """
        1 scenario passed, 0 failed, 1 skipped
        """
      And the command output should contain:
        """
        SKIP-SCENARIO: Alice and Bob
        Scenario: Alice in China
          When another step passes ... passed
        """
      But the command output should not contain:
        """
        Scenario: Alice and Bob
        SKIP-FEATURE: Alice and Bob
        """
      And the command output should not contain "Scenario: Alice and Bob"


    Scenario: Formatter is not called with skip in before_feature hook
      Given a file named "features/bob.feature" with:
        """
        @skip
        Feature: Bob
          Scenario: Bob and Alice
            Given a step passes
          Scenario: Bob in China
            When another step passes
        """
      When I run "behave -f plain features/bob.feature"
      Then it should pass with:
        """
        SKIP-FEATURE: Bob
        0 features passed, 0 failed, 1 skipped
        0 scenarios passed, 0 failed, 2 skipped
        """
      But the command output should not contain:
        """
        Feature: Bob
        SKIP-FEATURE: Bob
        """
      And the command output should not contain "Feature: Bob"
      And the command output should not contain "Scenario: Bob and Alice"
      And the command output should not contain "Scenario: Bob in China"
      And note that "all scenarios of the feature are also skipped"
@issue
@unicode
Feature: Issue #424 -- Unicode output problem when fails in nested steps

    . HINTS:
    .   * Python step file should have encoding line (# -*- coding: ... -*-)
    .   * Assert failure message should use unicode-string instead of byte-string

    Scenario:
      Given a new working directory
      And a file named "features/steps/pass_steps.py" with:
        """
        from behave import step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        """
      And a file named "features/steps/steps.py" with:
        """
        # -*- coding: UTF-8 -*-
        # NOTE: Python2 requires encoding to decode special chars correctly.
        from behave import step
        @step('I press the big red button')
        def step_press_red_button(context):
            assert False, u"Ungltiger Wert"  # HINT: Special chars require Unicode.
        @step('I call the nested step with the "red button"')
        def step_press_red_button(context):
            context.execute_steps(u'When I press the big red button')
        """
      And a file named "behave.ini" with:
          """
          [behave]
          show_timings = false
          """
      And a file named "features/alice.feature" with:
        """
        Feature:
          Scenario: Use step directly
            When I press the big red button
          Scenario: Use nested step
            Given another step passes
            When I call the nested step with the "red button"
        """
      When I run "behave -f plain features/alice.feature"
      Then it should fail with:
        """
        0 scenarios passed, 2 failed, 0 skipped
        1 step passed, 2 failed, 0 skipped, 0 undefined
        """
      And the command output should contain:
        """
        Scenario: Use step directly
          When I press the big red button ... failed
        Assertion Failed: Ungltiger Wert
        Scenario: Use nested step
          Given another step passes ... passed
          When I call the nested step with the "red button" ... failed
        Assertion Failed: FAILED SUB-STEP: When I press the big red button
        Substep info: Assertion Failed: Ungltiger Wert
        """
@issue
@junit
Feature: Issue #446 -- Support scenario hook-errors with JUnitReporter

  . Currently, when a hook error occurs in:
  .
  .   * before_scenario()
  .   * after_scenario()
  .
  . a sanity check in the JUnitReporter prevents sane JUnit XML output.


    @setup
    Scenario: Skip scenario without steps
      Given a new working directory
      And a file named "features/steps/pass_steps.py" with:
        """
        from behave import step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        """
      And a file named "features/before_scenario_failure.feature" with:
        """
        Feature: Alice
          @hook_failure.before_scenario
          Scenario: A1
            Given a step passes
        """
      And a file named "features/after_scenario_failure.feature" with:
        """
        Feature: Bob
          @hook_failure.after_scenario
          Scenario: B1
            Given another step passes
        """
      And a file named "features/environment.py" with:
        """
        def cause_hook_failure():
            raise RuntimeError("OOPS")
        def before_scenario(context, scenario):
            if "hook_failure.before_scenario" in scenario.tags:
                cause_hook_failure()
        def after_scenario(context, scenario):
            if "hook_failure.after_scenario" in scenario.tags:
                cause_hook_failure()
        """
      And a file named "behave.ini" with:
        """
        [behave]
        show_timings = false
        [behave.userdata]
        behave.reporter.junit.show_timestamp = False
        behave.reporter.junit.show_hostname = False
        """

    @not.with_python.version=3.8
    Scenario: Hook error in before_scenario()
      When I run "behave -f plain --junit features/before_scenario_failure.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the command output should contain:
        """
        HOOK-ERROR in before_scenario: RuntimeError: OOPS
        """
      And the file "reports/TESTS-before_scenario_failure.xml" should contain:
        """
        <testsuite errors="1" failures="0" name="before_scenario_failure.Alice" skipped="0" tests="1"
        """
      And the file "reports/TESTS-before_scenario_failure.xml" should contain:
        """
        <error message="HOOK-ERROR in before_scenario: RuntimeError: OOPS" type="RuntimeError">
        """
      And the file "reports/TESTS-before_scenario_failure.xml" should contain:
        """
        File "features/environment.py", line 6, in before_scenario
          cause_hook_failure()
        File "features/environment.py", line 2, in cause_hook_failure
          raise RuntimeError("OOPS")
        """
      And note that "the traceback is contained in the XML element <error/>"


    @use.with_python.version=3.8
    Scenario: Hook error in before_scenario()
      When I run "behave -f plain --junit features/before_scenario_failure.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the command output should contain:
        """
        HOOK-ERROR in before_scenario: RuntimeError: OOPS
        """
      And the file "reports/TESTS-before_scenario_failure.xml" should contain:
        """
        <testsuite name="before_scenario_failure.Alice" tests="1" errors="1" failures="0" skipped="0"
        """
        # -- HINT FOR: Python < 3.8
        # <testsuite errors="1" failures="0" name="before_scenario_failure.Alice" skipped="0" tests="1"
      And the file "reports/TESTS-before_scenario_failure.xml" should contain:
        """
        <error type="RuntimeError" message="HOOK-ERROR in before_scenario: RuntimeError: OOPS">
        """
        # -- HINT FOR: Python < 3.8
        # <error message="HOOK-ERROR in before_scenario: RuntimeError: OOPS" type="RuntimeError">
      And the file "reports/TESTS-before_scenario_failure.xml" should contain:
        """
        File "features/environment.py", line 6, in before_scenario
          cause_hook_failure()
        File "features/environment.py", line 2, in cause_hook_failure
          raise RuntimeError("OOPS")
        """
      And note that "the traceback is contained in the XML element <error/>"


    @not.with_python.version=3.8
    Scenario: Hook error in after_scenario()
      When I run "behave -f plain --junit features/after_scenario_failure.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the command output should contain:
        """
          Scenario: B1
            Given another step passes ... passed
        HOOK-ERROR in after_scenario: RuntimeError: OOPS
        """
      And the file "reports/TESTS-after_scenario_failure.xml" should contain:
        """
        <testsuite errors="1" failures="0" name="after_scenario_failure.Bob" skipped="0" tests="1"
        """
      And the file "reports/TESTS-after_scenario_failure.xml" should contain:
        """
        <error message="HOOK-ERROR in after_scenario: RuntimeError: OOPS" type="RuntimeError">
        """
      And the file "reports/TESTS-after_scenario_failure.xml" should contain:
        """
        File "features/environment.py", line 10, in after_scenario
          cause_hook_failure()
        File "features/environment.py", line 2, in cause_hook_failure
          raise RuntimeError("OOPS")
        """
      And note that "the traceback is contained in the XML element <error/>"


    @use.with_python.version=3.8
    Scenario: Hook error in after_scenario()
      When I run "behave -f plain --junit features/after_scenario_failure.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the command output should contain:
        """
          Scenario: B1
            Given another step passes ... passed
        HOOK-ERROR in after_scenario: RuntimeError: OOPS
        """
      And the file "reports/TESTS-after_scenario_failure.xml" should contain:
        """
        <testsuite name="after_scenario_failure.Bob" tests="1" errors="1" failures="0" skipped="0"
        """
        # -- HINT FOR: Python < 3.8
        # <testsuite errors="1" failures="0" name="after_scenario_failure.Bob" skipped="0" tests="1"
      And the file "reports/TESTS-after_scenario_failure.xml" should contain:
        """
        <error type="RuntimeError" message="HOOK-ERROR in after_scenario: RuntimeError: OOPS">
        """
        # -- HINT FOR: Python < 3.8
        # <error message="HOOK-ERROR in after_scenario: RuntimeError: OOPS" type="RuntimeError">
      And the file "reports/TESTS-after_scenario_failure.xml" should contain:
        """
        File "features/environment.py", line 10, in after_scenario
          cause_hook_failure()
        File "features/environment.py", line 2, in cause_hook_failure
          raise RuntimeError("OOPS")
        """
      And note that "the traceback is contained in the XML element <error/>"
@issue
@unicode
Feature: Issue #449 -- Unicode output problem when fails with Russion text

  . Either Exception text (as summary) or traceback python line shows
  . special characters correctly.

  Scenario:
    Given a new working directory
    And a file named "features/steps/problematic_steps.py" with:
      """
      # -*- coding: UTF-8 -*-
      # NOTE: Python2 requires encoding to decode special chars correctly.
      from behave import step
      from hamcrest.core import assert_that, equal_to
      @step("Russian text")
      def step_russian_text(stop):
          assert_that(False, equal_to(True), u"  ") # cyrillic
      """
    And a file named "behave.ini" with:
        """
        [behave]
        show_timings = false
        """
    And a file named "features/syndrome.feature" with:
      """
      Feature:
        Scenario:
          Given Russian text
      """
    When I run "behave -f plain features/syndrome.feature"
    Then it should fail with:
      """
      Scenario:
        Given Russian text ... failed
      Assertion Failed:   
      """
    But the command output should not contain:
      """
      Assertion Failed: 'ascii' codec can't encode characters in position
      """
@issue
@unicode
Feature: Issue #453 -- Unicode output problem when Exception is raised in step

  . Either Exception text (as summary) or traceback python line shows
  . special characters incorrectly.
  .
  . Result (of failed step):
  .     File "features/steps/steps.py", line 8, in foo
  .        raise Exception(u" ") <-- This is not
  .   Exception:   <-- This is OK
    Scenario:
      Given a new working directory
      And a file named "features/steps/problematic_steps.py" with:
        """
        # -*- coding: UTF-8 -*-
        from behave import step
        @step(u'an exception with special chars is raised')
        def step_exception_raised(context):
            raise Exception(u" ")
        """
      And a file named "features/syndrome.feature" with:
        """
        Feature:
          Scenario:
            Given an exception with special chars is raised
        """
      When I run "behave -f plain features/syndrome.feature"
      Then it should fail with:
        """
        Scenario:
          Given an exception with special chars is raised ... failed
        """
      And the command output should contain:
        """
          File "features/steps/problematic_steps.py", line 6, in step_exception_raised
            raise Exception(u" ")
        Exception:  
        """
@not_reproducible
@issue
Feature: Issue #457 -- Double-quotes in error messages of JUnit XML reports

    STATUS: Problem is currently not reproducible.
    XML attributes are escaped correctly even when double-quotes are used.

    @setup
    Scenario: Feature Setup
      Given a new working directory
      And a file named "features/steps/fail_steps.py" with:
        """
        from behave import step
        @step('{word:w} step fails with message')
        def step_fails(context, word):
            assert context.text
            assert False, "FAILED: "+ context.text
        @step('{word:w} step fails with error and message')
        def step_fails2(context, word):
            assert context.text
            raise RuntimeError(context.text)
        """


    @not.with_python.version=3.8
    Scenario: Use failing assertation in a JUnit XML report
      Given a file named "features/fails1.feature" with:
        """
        Feature:
          Scenario: Alice
            Given a step fails with message:
              '''
              My name is "Alice"
              '''
        """
      When I run "behave --junit features/fails1.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the file "reports/TESTS-fails1.xml" should contain:
        """
        <failure message="FAILED: My name is &quot;Alice&quot;"
        """

    @use.with_python.version=3.8
    Scenario: Use failing assertation in a JUnit XML report
      Given a file named "features/fails1.feature" with:
        """
        Feature:
          Scenario: Alice
            Given a step fails with message:
              '''
              My name is "Alice"
              '''
        """
      When I run "behave --junit features/fails1.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the file "reports/TESTS-fails1.xml" should contain:
        """
        <failure type="AssertionError" message="FAILED: My name is &quot;Alice&quot;">
        """
        # -- HINT FOR: Python < 3.8
        # <failure message="FAILED: My name is &quot;Alice&quot;"


    @not.with_python.version=3.8
    Scenario: Use exception in a JUnit XML report
      Given a file named "features/fails2.feature" with:
        """
        Feature:
          Scenario: Bob
            Given a step fails with error and message:
              '''
              My name is "Bob" and <here> I am
              '''
        """
      When I run "behave --junit features/fails2.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the file "reports/TESTS-fails2.xml" should contain:
        """
        <error message="My name is &quot;Bob&quot; and &lt;here&gt; I am"
        """

    @use.with_python.version=3.8
    Scenario: Use exception in a JUnit XML report
      Given a file named "features/fails2.feature" with:
        """
        Feature:
          Scenario: Bob
            Given a step fails with error and message:
              '''
              My name is "Bob" and <here> I am
              '''
        """
      When I run "behave --junit features/fails2.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the file "reports/TESTS-fails2.xml" should contain:
        """
        <error type="RuntimeError" message="My name is &quot;Bob&quot; and &lt;here&gt; I am">
        """
        # -- HINT FOR: Python < 3.8
        # <error message="My name is &quot;Bob&quot; and &lt;here&gt; I am"
@issue
Feature: Issue #462-- Invalid JSON output when --include option selects no features

  . Invalid JSON output is generated when no features are selected in a test-run.
  . For example, this may be the case when the --include option is used.


    Background:
      Given a new working directory
      And a file named "features/steps/pass_steps.py" with:
        """
        from behave import step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        """
      And a file named "features/passing.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
        """


    Scenario: Include Option selects no feature files
      When I run "behave -f json -i __unknown__.feature"
      Then it should pass with:
        """
        0 features passed, 0 failed, 0 skipped
        0 scenarios passed, 0 failed, 0 skipped
        """
      And the command output should contain:
        """
        [
        ]
        """
@issue
Feature: Issue #467 -- Scenario status when scenario w/o steps is skipped

  . The scenario.status should be "skipped"
  . if you try to skip a scenario without any steps.


    Scenario: Skip scenario without steps
      Given a new working directory
      And a file named "features/steps/pass_steps.py" with:
        """
        from behave import step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        """
      And a file named "features/without_steps.feature" with:
        """
        Feature:
          @skip_this
          Scenario: Without steps
        """
      And a file named "features/environment.py" with:
        """
        def before_scenario(context, scenario):
            if "skip_this" in scenario.tags:
                scenario.skip()
        """
      When I run "behave -f plain features/without_steps.feature"
      Then it should pass with:
        """
        Feature:
          Scenario: Without steps
        0 features passed, 0 failed, 1 skipped
        0 scenarios passed, 0 failed, 1 skipped
        """
      But note that "the scenario without steps is skipped"
@issue
@unicode
@not_reproducible
Feature: Issue #487 -- UnicodeEncodeError with ZBSP in multi-line text

    . NOTE: I use ZBSP (zero-width space) in multiline text
    . Traceback (most recent call last):
    .  File "/usr/bin/behave-2", line 9, in <module>
    .    load_entry_point('behave==1.2.5', 'console_scripts', 'behave')()
    .  File "/usr/lib/python2.7/site-packages/behave/__main__.py", line 111, in main
    .     print(u"ParseError: %s" % e)
    . UnicodeEncodeError: 'ascii' codec can't encode characters in position 92-103: ordinal not in range(128)
    .
    . ANALYSIS:
    .   ParseError indicates that the problem occured while parsing the
    .   feature file. Feature file encoding is assumed

    @not.with_ci=appveyor
    Scenario:
      Given a new working directory
      And a file named "features/steps/pass_steps.py" with:
        """
        from behave import step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        """
      And a file named "features/steps/steps.py" with:
        """
        # -*- coding: latin-1 -*-
        from __future__ import print_function
        from behave import step
        @step('I use {special_unicode_char:w} in text')
        def step_use_ZBSP_with_text(context, special_unicode_char):
            assert context.text
            print(u"TEXT: %s" % context.text)
        """
      And a file named "behave.ini" with:
          """
          [behave]
          show_timings = false
          """
      And a file named "features/syndrome.feature" with:
        """
        Feature:
          Scenario Outline: Use special unicode char (<comment>)
            Given I use ZBSP in text:
              '''
              HERE we use a ==><special_unicode_char><== SPECIAL UNICODE CHAR.
              '''
           Examples:
              | special_unicode_char | comment |
              |                     | MACOS command key symbol |
              |                     | copyright sign           |
              |                     | Euro sign (currency)     |
              | xxx XXX              | special space            |
        """
      When I run "behave -f plain features/syndrome.feature"
      Then it should pass with:
        """
        4 scenarios passed, 0 failed, 0 skipped
        """
      And the command output should contain:
        '''
        Scenario Outline: Use special unicode char (MACOS command key symbol) -- @1.1
          Given I use ZBSP in text ... passed
            """
            HERE we use a ==><== SPECIAL UNICODE CHAR.
            """
        Scenario Outline: Use special unicode char (copyright sign) -- @1.2
          Given I use ZBSP in text ... passed
            """
            HERE we use a ==><== SPECIAL UNICODE CHAR.
            """
        Scenario Outline: Use special unicode char (Euro sign (currency)) -- @1.3
          Given I use ZBSP in text ... passed
            """
            HERE we use a ==><== SPECIAL UNICODE CHAR.
            """
        Scenario Outline: Use special unicode char (special space) -- @1.4
          Given I use ZBSP in text ... passed
            """
            HERE we use a ==>xxx XXX<== SPECIAL UNICODE CHAR.
            """
        '''
@issue
@user_error
@python2.problem
Feature: Issue #506 -- Behave stops on error

    . ANALYSIS:
    .   Using exception.__cause__ = original_exception causes problems in Python2
    .   When you use the Python3 chained-exception mechanism,
    .   you should better ensure that the "original_exception.__traceback__" attribute
    .   exists. Otherwise, a new exception (missing attribute) is raised
    .   when you format the traceback,

    Scenario:
      Given a new working directory
      And a file named "features/steps/pass_steps.py" with:
        """
        from behave import step
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        """
      And a file named "features/steps/steps.py" with:
        """
        from behave import when, then
        from behave._types import ChainedExceptionUtil
        import copy
        @when('I bad chained-exception causes my step to fail')
        def step_bad_usage_of_chained_exception(context):
            # -- BAD IMPLEMENATION:
            exception = ZeroDivisionError('integer division or modulo by zero')
            exception.__cause__ = copy.copy(exception)
            raise exception
        @when('a chained-exception causes my step to fail')
        def step_chained_exception_causes_failure(context):
            try:
                raise ZeroDivisionError("OOPS-1")
            except ZeroDivisionError as e:
                e2 = RuntimeError("OOPS-2")
                ChainedExceptionUtil.set_cause(e2, e)
                raise e2
        @then('this step must be executed')
        def step_check_step(context):
            pass
        """
      And a file named "features/syndrome.feature" with:
        """
        Feature: Failing step which can lead to stop behave
          @failing
          Scenario: Run stopping behave scenario
            When a chained-exception causes my step to fail
            Then this step must be executed
        """
      When I run "behave -f plain features/syndrome.feature"
      Then it should fail with:
        """
        0 scenarios passed, 1 failed, 0 skipped
        """
      And the command output should contain:
        """
          ZeroDivisionError: OOPS-1
        The above exception was the direct cause of the following exception:
        Traceback (most recent call last):
        """
      And the command output should contain:
        """
          File "features/steps/steps.py", line 19, in step_chained_exception_causes_failure
            raise e2
        RuntimeError: OOPS-2
        """
@issue
@junit
@wip
Feature: Issue #510 -- JUnit XML output is not well-formed (in some cases)

  . Special control characters in JUnit stdout/stderr sections
  . are directly written to CDATA XML sections.
  .
  . According to the XML charset specification only the following unicode
  . codepoints (characters) are allowed in a CDATA section:
  .
  .   Char ::=  #x9 | #xA | #xD | [#x20-#xD7FF] | [#xE000-#xFFFD] | [#x10000-#x10FFFF]
  .   /* any Unicode character, excluding the surrogate blocks, FFFE, and FFFF. */
  .
  . [XML-charsets] "The normative reference is XML 1.0 (Fifth Edition),
  .     section 2.2, https://www.w3.org/TR/REC-xml/#charsets
  @use.with_xmllint=yes
  @xfail
  Scenario:
    Given a new working directory
    And a file named "features/steps/special_char_steps.py" with:
      """
      # -*- coding: UTF-8 -*-
      from __future__ import print_function
      from behave import step

      @step(u'we print ^D')
      def step_print_special_char_control_d(context):
          print(u"\004")
      """
    And a file named "features/special_char.feature" with:
      """
      Feature: An illegal char
        Scenario: Control-D
          When we print ^D
      """
    When I run "behave --junit features/special_char.feature"
    Then it should pass with:
      """
      1 scenario passed, 0 failed, 0 skipped
      """
    When I run "xmllint reports/TESTS-special_char.xml"
    Then it should pass
    And the command output should not contain "parser error"
    And the command output should not contain:
      """
      reports/TESTS-special_char.xml:12: parser error : PCDATA invalid Char value 4
      """
    And note that "xmllint reports additional correlated errors"
@issue
Feature: Issue 547 -- behave crashes when adding a step definition with optional parts

  . NOTE: cfparse/parse matcher conflict issue w/ CTOR init code.

    Scenario: Syndrome w/ cfparse
      Given a new working directory
      And a file named "features/environment.py" with:
        """
        from behave import register_type, use_step_matcher
        import parse
        @parse.with_pattern(r"optional\s+")
        def parse_optional_word(text):
            return text.strip()
        use_step_matcher("cfparse")
        register_type(opt_=parse_optional_word)
        """
      And a file named "features/steps/steps.py" with:
          """
          from behave import step
          @step(u'some {:opt_?}word')
          def step_impl(context, opt_):
              pass
          """
      And a file named "features/alice.feature" with:
          """
          Feature: Alice
            Scenario: Bob
              Given some optional word
          """
      When I run "behave -f plain features/alice.feature"
      Then it should pass
      And the command output should not contain:
        """
        ValueError: format spec u'opt_?' not recognised
        """
@issue
@mistaken
Feature: Issue 573 Select scenarios fails with empty Scenarios

    @setup
    Scenario: Test Setup
        Given a new working directory
        And a file named "features/steps/steps.py" with:
            """
            from behave import step
            @step('a step passes')
            def step_passes(context):
                pass
            """
        And a file named "features/syndrome.feature" with:
            """
            Feature: Alice
                Scenario: Empty (no steps)
                Scenario: Not Empty (with steps)
                    When a step passes
            """
        And a file named "behave.ini" with:
            """
            [behave]
            show_skipped = false
            show_timings = false
            """

    Scenario: Select scenarios by name in dry-run mode
        When I run "behave -f plain --name="Not Empty \(with steps\)" --dry-run features/"
        Then the command output should contain:
            """
            Feature: Alice
              Scenario: Not Empty (with steps)
                  When a step passes ... untested
            """
        And it should pass with:
            """
            0 features passed, 0 failed, 0 skipped, 1 untested
            0 scenarios passed, 0 failed, 1 skipped, 1 untested
            0 steps passed, 0 failed, 0 skipped, 0 undefined
            """

    Scenario: Select scenarios by name and run them
        When I run "behave -f plain --name="Not Empty \(with steps\)" features/"
        Then the command output should contain:
            """
            Feature: Alice
              Scenario: Not Empty (with steps)
                  When a step passes ... passed
            """
        And it should pass with:
            """
            1 feature passed, 0 failed, 0 skipped
            1 scenario passed, 0 failed, 1 skipped
            1 step passed, 0 failed, 0 skipped, 0 undefined
            """

    Scenario: Select scenarios by name with partial name and run them
        When I run "behave -f plain --name="Not Empty" features/"
        Then the command output should contain:
            """
            Feature: Alice
              Scenario: Not Empty (with steps)
                  When a step passes ... passed
            """
        And it should pass with:
            """
            1 feature passed, 0 failed, 0 skipped
            1 scenario passed, 0 failed, 1 skipped
            1 step passed, 0 failed, 0 skipped, 0 undefined
            """
@issue
Feature: Issue #597 -- Steps with accented letters doesn't seem to work


  Background:
    Given a new working directory
    And a file named "features/french.feature" with:
      """
      # language: fr
      Fonctionnalit: Alice
        Scnario: A1
          Soit all
          Quand comment
          Alors cava
      """
    And a file named "behave.ini" with:
      """
      [behave]
      show_timings = false
      """

  Scenario: Passing w/o Encoding-Hint in Steps File (case: py2, py3)
    Given a file named "features/steps/french_steps.py" with:
      """
      # -*- coding: UTF-8 -*-
      from behave import given, when, then
      @given(u'all')
      def given_step_alle(ctx):
          pass
      @when(u'comment')
      def when_step_comment(ctx):
          pass
      @then(u'cava')
      def then_step_cava(ctx):
          pass
      """
    When  I run "behave -f plain features/"
    Then it should pass with:
      """
      Fonctionnalit: Alice
        Scnario: A1
          Soit all ... passed
          Quand comment ... passed
          Alors cava ... passed
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """

  @only.with_python2=true
  Scenario: Failing w/o Encoding-Hint in Steps File (case: python2)
    Given a file named "features/steps/french_steps.py" with:
      """
      from behave import given, when, then
      @given(u'all')
      def given_step_alle(ctx):
          pass
      @when(u'comment')
      def when_step_comment(ctx):
          pass
      @then(u'cava')
      def then_step_cava(ctx):
          pass
      """
    When  I run "behave -f plain features/"
    Then it should fail with:
      """
      0 features passed, 1 failed, 0 skipped
      0 scenarios passed, 1 failed, 0 skipped
      0 steps passed, 0 failed, 2 skipped, 1 undefined
      """
    And the command output should contain:
      """
      Scnario: A1
        Soit all ... undefined
      """
    And the command output should contain:
      """
      You can implement step definitions for undefined steps with these snippets:
      @given(u'all')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Given all')
      """
    But note that "python2 uses encoding=ascii"
    And note that "encoding-hint in steps file solves the problem"


  @not.with_python2=true
  Scenario: Passing w/o Encoding-Hint in Steps File (case: python3)
    Given a file named "features/steps/french_steps.py" with:
      """
      from behave import given, when, then
      @given(u'all')
      def given_step_alle(ctx):
          pass
      @when(u'comment')
      def when_step_comment(ctx):
          pass
      @then(u'cava')
      def then_step_cava(ctx):
          pass
      """
    When  I run "behave -f plain features/"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Scnario: A1
        Soit all ... passed
      """
    And the command output should not contain:
      """
      @given(u'all')
      def step_impl(context):
          raise NotImplementedError(u'STEP: Given all')
      """
    But note that "python3 discovers encoding (or uses encoding=UTF-8)"
@issue
Feature: Issue #606 -- Name option with special unicode chars


  Background:
    Given a new working directory
    And a file named "features/alice.feature" with:
      """
      Feature: Alice
        Scenario: rgernis ist berall
          Given a step passes
        Scenario: My second rgernis
          When another step passes
        Scenario: Unused
          Then some step passes
      """
    And a file named "features/steps/passing_steps.py" with:
      """
      from behave import step
      @step(u'{word:w} step passes')
      def step_passes(context, word):
          pass
      """
    And a file named "behave.ini" with:
      """
      [behave]
      show_timings = false
      """

  Scenario: Use special unicode chars in --name options
    When  I run "behave -f plain --name rgernis features/"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      2 scenarios passed, 0 failed, 1 skipped
      2 steps passed, 0 failed, 1 skipped, 0 undefined
      """
    And the command output should contain:
      """
      Scenario: rgernis ist berall
        Given a step passes ... passed
      Scenario: My second rgernis
        When another step passes ... passed
      """
    But the command output should not contain:
      """
      UnicodeDecodeError: 'ascii' codec can't decode byte
      """
Feature: Issue #631 -- Scenario Outline variables not possible in table headings

  Background:
    Given a new working directory
    And a file named "features/alice.feature" with:
      """
      Feature:
        Scenario Outline: Use <method>
          When the following request is sent
             | <method>     |
             | /example-url/<method> |
          Then a step passes
          Examples: Supported methods
            | method |
            | GET    |
            | POST   |
      """
    And a file named "features/steps/passing_steps.py" with:
      """
      from behave import step
      @step(u'{word:w} step passes')
      def step_passes(context, word):
          pass
      """
    And a file named "features/steps/problematic_steps.py" with:
      """
      from behave import when
      @when(u'the following request is sent')
      def step_passes(context):
          assert context.table, "REQUIRE: step.table exists"
          pass
      """
    And a file named "behave.ini" with:
      """
      [behave]
      show_timings = false
      """

  Scenario: Check Syndrome
    When  I run "behave -f plain features/"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      2 scenarios passed, 0 failed, 0 skipped
      4 steps passed, 0 failed, 0 skipped, 0 undefined
      """
    And the command output should not contain "<method>"
    And note that "the resulting output should look like"
    And the command output should contain:
      """
      Scenario Outline: Use GET -- @1.1 Supported methods
        When the following request is sent ... passed
          | GET              |
          | /example-url/GET |
         Then a step passes ... passed
      Scenario Outline: Use POST -- @1.2 Supported methods
        When the following request is sent ... passed
          | POST              |
          | /example-url/POST |
        Then a step passes ... passed
      """
@wip
Feature: Issue #643 -- Unable to add comments on table data lines

  Background:
    Given a new working directory
    And a file named "features/steps/passing_steps.py" with:
      """
      from behave import step
      @step(u'{word:w} step passes')
      def step_passes(context, word):
          pass
      """
    And a file named "behave.ini" with:
      """
      [behave]
      show_timings = false
      """

  Scenario: Check Syndrome
    Given a file named "features/syndrome_643.feature" with:
      """
      Feature:
        Scenario Outline:
          Given a step passes
          Examples:
            |  name  |   size  |
            |   me   | 1048576 | # 1MB
            | myself | 2097152 | # 2MB
            |   I    | 4194304 | # 4MB
      """
    When  I run "behave -f plain features/syndrome_643.feature"
    Then it should fail with:
      """
      ParserError: Failed to parse "{__WORKDIR__}/features/syndrome_643.feature": Malformed table at line 8
      """

  Scenario: Check Syndrome -- Variant B
    Given a file named "features/syndrome_643B.feature" with:
      """
      Feature:
        Scenario Outline:
          Given a step passes
          Examples:
            |  name  |   size  | # Headings
            |   me   | 1048576 | # 1MB
            | myself | 2097152 | # 2MB
            |   I    | 4194304 | # 4MB
      """
    When  I run "behave -f plain features/syndrome_643B.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      3 scenarios passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """
    But note that "providing a comment after each table row 'fixes' the parse-problem, too"
@not.with_python2=true
@issue
Feature: Issue #657 -- Allow async steps with timeouts to fail when they raise exceptions


    @use.with_python.version=3.5
    @use.with_python.version=3.6
    @async_step_fails
    Scenario: Use @async_run_until_complete and async-step fails
      Given a new working directory
      And a file named "features/steps/async_steps_fails35.py" with:
        """
        from behave import step
        from behave.api.async_step import async_run_until_complete
        @step('an async-step passes')
        @async_run_until_complete
        async def step_async_step_passes(context):
            pass
        @step('an async-step fails')
        @async_run_until_complete(timeout=2)
        async def step_async_step_fails(context):
            assert False, "XFAIL in async-step"
        """
      And a file named "features/async_failure.feature" with:
        """
        Feature:
          Scenario:
            Given an async-step passes
            When an async-step fails
            Then an async-step passes
        """
      When I run "behave -f plain --show-timings features/async_failure.feature"
      Then it should fail with:
        """
        1 step passed, 1 failed, 1 skipped, 0 undefined
        """
      And the command output should contain:
        """
        Assertion Failed: XFAIL in async-step
        """
      And the command output should contain:
        """
        When an async-step fails ... failed in 0.0
        """
      But note that "the async-step should fail immediately"
@issue
@mistaken
Feature: Issue #673 -- @given and @Given step decorators with wildcard import


    Scenario: Ensure that wildcard imports work for step decorators
      Given a new working directory
      And a file named "features/steps/wildcard_import_steps.py" with:
        """
        from behave import *
        @given(u'a step passes')
        def given_step_passes(context):
            pass
        @Given(u'another step passes')
        def given_step_passes2(context):
            pass
        @step('{word:w} step passes')
        def step_passes(context, word):
            pass
        """
      And a file named "features/basic.feature" with:
        """
        Feature:
          Scenario:
            Given a step passes
            And another step passes
            When some step passes
        """
      When I run "behave -f pretty --no-color features/basic.feature"
      Then it should pass with:
        """
        3 steps passed, 0 failed, 0 skipped, 0 undefined
        """
      And the command output should contain:
        """
        Scenario:                 # features/basic.feature:2
          Given a step passes     # features/steps/wildcard_import_steps.py:3
          And another step passes # features/steps/wildcard_import_steps.py:7
          When some step passes   # features/steps/wildcard_import_steps.py:11
        """
@issue
@sequential
@not.with_platform=windows
Feature: Issue #675 -- Feature files cannot be found within symlink directories

  NOTES:
    Test may only work on UNIX-like system (Linux, macOS, FreeBSD, ...).
    Test requires that all scenarios are run (not: ordering-idenpendent).


  Background: Setup Directory Structure
    Given a new working directory
    And a file named "features/pass.feature" with:
      """
      Feature: Issue 675
      Scenario: this too shall pass
        Given this
        When this
        Then this
      """
    And a file named "second/steps/steps.py" with:
      """
      from behave import step
      @step(u'this')
      def step_impl(context):
        pass
      """

  Scenario: Without Symlink to Feature Directory (expected to fail)
    When I run "behave -f plain second"
    Then it should fail
    And the command output should contain "ConfigError: No feature files in"

  Scenario: With Symlink to Feature Directory (expected to pass)
    When I create a symlink from "../features" to "second/features"
    And I run "behave -f plain second"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      3 steps passed, 0 failed, 0 skipped, 0 undefined
      """
@issue
@enhancement
Feature: Scenario Outlines shall support tags with commas

  @tag,with,commas @tag;with;semicolons
  Scenario: Scenario supports these tags
    Given I inspect the tags of the current scenario
    Then the tag "tag,with,commas" is contained
    And the tag "tag;with;semicolons" is contained

  @tag,with,commas @tag;with;semicolons
  Scenario Outline: Scenario Outline supports these tags
    Given I inspect the tags of the current scenario
    Then the tag "tag,with,commas" is contained
    And the tag "tag;with;semicolons" is contained

    Examples:
    | data  |
    | value |

  Scenario Outline: Scenario Outline supports tagged example
    Given I inspect the tags of the current scenario
    Then the tag "tag,with,commas" is contained
    And the tag "tag;with;semicolons" is contained

    @tag,with,commas @tag;with;semicolons
    Examples:
    | data  |
    | value |
@issue
Feature: Issue #713 -- Background section doesn't support descriptive paragraphs



  Background: Setup
    Given a new working directory
    And a file named "features/syndrome_713.feature" with:
      """
      Feature: Background Section Contains Descriptive text
        Per the documentation, behave supports the Gherkin standard
        The gherkin standard says that the Background section can contain descriptive text.
        (See: https://docs.cucumber.io/gherkin/reference/#descriptions )
        Background: Short Description is Here
          The A longer description should be permitted here.
          However, as of this writing, behave throws an error instead
          Given a step passes
        Scenario: Short Description Here
          This scenario is here to satisfy the syntactic requirements for a feature file.
          Given another step passes
      """
    And a file named "features/steps/use_step_library.py" with:
      """
      # -- REUSE STEPS:
      import behave4cmd0.passing_steps
      """

  Scenario: Use Background with Description
    When I run "behave -f plain features/syndrome_713.feature"
    Then it should pass with:
      """
      Feature: Background Section Contains Descriptive text
        Background: Short Description is Here
        Scenario: Short Description Here
          Given a step passes ... passed
          Given another step passes ... passed
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      2 steps passed, 0 failed, 0 skipped, 0 undefined
      """
    And the command output should not contain "Parser failure in state"
    And note that "the Background description was parsed."
@issue
@not_reproducible
Feature: Issue #766 -- UnicodeEncodeError in PrettyFormatter

  Explore the described problem.

  Scenario Outline:
    Given a step with name="<name>"

    Examples:
      | name | value | comment |
      |    | 123   | Use emoticon (smiley) in a table |

  Scenario:
    Given a step with table data:
      | name | value | comment |
      |    | 123   | Use emoticon (smiley) in a table |

  Scenario: Explore problem by using the pretty formatter
    Given a new working directory
    And a file named "features/syndrome_766.feature" with:
      """
      Feature: Alice
        Scenario Outline:
          Given a step with name="<name>"
          Examples:
            | name | value | comment |
            |    | 123   | Use emoticon (smiley) in a table |
      """
    And a file named "features/steps/issue766_steps.py" with:
      """
      from behave import given
      @given(u'a step with name="{name}"')
      def step_with_table_data(ctx, name):
          pass
      """
    When I run "behave -f pretty features/syndrome_766.feature"
    Then it should pass with:
      """
      1 feature passed, 0 failed, 0 skipped
      1 scenario passed, 0 failed, 0 skipped
      1 step passed, 0 failed, 0 skipped, 0 undefine
      """
    And the command output should not contain "UnicodeEncodeError"
    And the command output should not contain "Traceback"
@issue
Feature: Issue #772 -- Syndrome: ScenarioOutline with Examples keyword w/o Table



  Background: Setup
    Given a new working directory
    And a file named "features/syndrome_772.feature" with:
      """
      Feature: Examples without table
        Scenario Outline:
          Given a step passes
          When another step passes
          Examples: Without table
      """
    And a file named "features/steps/use_step_library.py" with:
      """
      # -- REUSE STEPS:
      import behave4cmd0.passing_steps
      """

  Scenario: Use ScenarioOutline with Examples keyword without table
    When I run "behave -f plain features/syndrome_772.feature"
    Then it should pass with:
      """
      Feature: Examples without table
      ERROR: ScenarioOutline.Examples: Has NO-TABLE syndrome (features/syndrome_772.feature:7)
      """
    And the command output should not contain "Parser failure in state"







